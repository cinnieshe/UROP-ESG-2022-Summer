{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b3cb64",
   "metadata": {},
   "source": [
    "# Fine-Tune CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be21e9d",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d2873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # store and load weight\n",
    "import pandas as pd # load data\n",
    "import nltk # text processing\n",
    "from nltk.stem import PorterStemmer # text processing\n",
    "from nltk.corpus import stopwords #text processing\n",
    "import numpy as np # one-hot vector\n",
    "import matplotlib.pyplot as plt # model analysis\n",
    "from itertools import chain # feature construction\n",
    "from collections import Counter # build feats-dict\n",
    "from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Embedding, Dropout, BatchNormalization, Activation, Input, \\\n",
    "    Conv1D, MaxPool1D, Flatten, Concatenate, Add\n",
    "\n",
    "stopwords = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc3cfbf",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8e9e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Input: string filename\n",
    "    Output: a pandas dataframe for the whole dataset after droping missing values\n",
    "    Support google colab or local environments\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # local environment\n",
    "        df = pd.read_csv(filename)\n",
    "        df = df.dropna(subset=['sentence', 'label']) ## drop missing values\n",
    "        return df\n",
    "    except:\n",
    "        # google colab environment\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        \n",
    "        df = pd.read_csv('/content/drive/MyDrive/' + filename)\n",
    "        df = df.dropna(subset=['sentence', 'label']) ## drop missing values\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb8b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    \"\"\"\n",
    "    Input: pandas dataframe\n",
    "    Output: training dataframe (81%), validation dataframe (9%), test dataframe (10%)\n",
    "    \"\"\"\n",
    "    df_train, df_val = train_test_split(df, stratify=df['label'],test_size=0.1, random_state=42)\n",
    "    \n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9a3ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    :param text: a doc with multiple sentences, type: str\n",
    "    return a word list, type: list\n",
    "    e.g.\n",
    "    Input: 'Text mining is to identify useful information.'\n",
    "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    \"\"\"\n",
    "    return nltk.word_tokenize(text)\n",
    "\n",
    "def stem(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of stemmed words, type: list\n",
    "    e.g.\n",
    "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
    "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "\n",
    "    return [ps.stem(token) for token in tokens]\n",
    "\n",
    "def n_gram(tokens, n=1):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    :param n: the corresponding n-gram, type: int\n",
    "    return a list of n-gram tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
    "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
    "    \"\"\"\n",
    "    if n == 1:\n",
    "        return tokens\n",
    "    else:\n",
    "        results = list()\n",
    "        for i in range(len(tokens)-n+1):\n",
    "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
    "            results.append(\" \".join(tokens[i:i+n]))\n",
    "        return results\n",
    "    \n",
    "def filter_stopwords(tokens):\n",
    "    \"\"\"\n",
    "    :param tokens: a list of tokens, type: list\n",
    "    return a list of filtered tokens, type: list\n",
    "    e.g.\n",
    "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
    "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
    "    \"\"\"\n",
    "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
    "\n",
    "def get_feats_dict(feats, min_freq=-1, max_freq=-1, max_size=-1):\n",
    "    \"\"\"\n",
    "    :param data: a list of features, type: list(list)\n",
    "    :param min_freq: the lowest fequency that the fequency of a feature smaller than it will be filtered out, type: int\n",
    "    :param max_freq: the highest fequency that the fequency of a feature larger than it will be filtered out, type: int\n",
    "    :param max_size: the max size of feature dict, type: int\n",
    "    return a feature dict that maps features to indices, sorted by frequencies\n",
    "    # Counter document: https://docs.python.org/3.6/library/collections.html#collections.Counter\n",
    "    \"\"\"\n",
    "    # count all features\n",
    "    feat_cnt = Counter(feats) # [\"text\", \"text\", \"mine\"] --> {\"text\": 2, \"mine\": 1}\n",
    "    if max_size > 0 and min_freq == -1 and max_freq == -1:\n",
    "        valid_feats = [f for f, cnt in feat_cnt.most_common(max_size)]\n",
    "    else:\n",
    "        valid_feats = list()\n",
    "        for f, cnt in feat_cnt.most_common():\n",
    "            if (min_freq == -1 or cnt >= min_freq) and \\\n",
    "                (max_freq == -1 or cnt <= max_freq):\n",
    "                valid_feats.append(f)\n",
    "    if max_size > 0 and len(valid_feats) > max_size:\n",
    "        valid_feats = valid_feats[:max_size]        \n",
    "    print(\"Size of features:\", len(valid_feats))\n",
    "    \n",
    "    # build a mapping from features to indices\n",
    "    feats_dict = dict(zip(valid_feats, range(len(valid_feats))))\n",
    "    return feats_dict\n",
    "\n",
    "def get_onehot_vector(feats, feats_dict):\n",
    "    \"\"\"\n",
    "    :param feats: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
    "    for f in feats:\n",
    "        # get the feature index, return -1 if the feature is not existed\n",
    "        f_idx = feats_dict.get(f, -1)\n",
    "        if f_idx != -1:\n",
    "            # set the corresponding element as 1\n",
    "            vector[f_idx] = 1\n",
    "    return vector\n",
    "\n",
    "# Get index vector\n",
    "def get_index_vector(feats, feats_dict, max_len):\n",
    "    \"\"\"\n",
    "    :param feats: a list of features, type: list\n",
    "    :param feats_dict: a dict from features to indices, type: dict\n",
    "    :param feats: a list of features, type: list\n",
    "    return a feature vector,\n",
    "    \"\"\"\n",
    "    # initialize the vector as all zeros\n",
    "    vector = np.zeros(max_len, dtype=np.int64)\n",
    "    for i, f in enumerate(feats):\n",
    "        if i == max_len:\n",
    "            break\n",
    "        # get the feature index, return 1 (<unk>) if the feature is not existed\n",
    "        try:\n",
    "            vector[i] = feats_dict[f]\n",
    "        except KeyError:\n",
    "            vector[i] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6a83f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_CNN(input_length, vocab_size, embedding_size,\n",
    "              hidden_size, output_size,\n",
    "              kernel_sizes, num_filters, num_mlp_layers,\n",
    "              padding=\"valid\",\n",
    "              strides=1,\n",
    "              activation=\"relu\",\n",
    "              dropout_rate=0.0,\n",
    "              batch_norm=False,\n",
    "              l2_reg=0.0,\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"SGD\",\n",
    "              learning_rate=0.1):\n",
    "\n",
    "    x = Input(shape=(input_length,))\n",
    "    \n",
    "    #### word representation layer ####\n",
    "    emb = Embedding(input_dim=vocab_size, output_dim=embedding_size)(x)\n",
    "    \n",
    "    #### convolutional and pooling layers ####\n",
    "    cnn_results = list()\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # add convolutional layer\n",
    "        conv = Conv1D(filters=num_filters, kernel_size=kernel_size, padding=padding, strides=strides)(emb)\n",
    "        # add batch normalization layer\n",
    "        if batch_norm:\n",
    "            conv = BatchNormalization()(conv)\n",
    "        # add activation\n",
    "        conv = Activation(activation)(conv)\n",
    "        # add max-pooling\n",
    "        maxpool = MaxPool1D(pool_size=(input_length-kernel_size)//strides+1)(conv)\n",
    "        cnn_results.append(Flatten()(maxpool))\n",
    "    \n",
    "    ##### Fully Connected Layer ####\n",
    "    h = Concatenate()(cnn_results) if len(kernel_sizes) > 1 else cnn_results[0]\n",
    "    h = Dropout(dropout_rate, seed=0)(h)\n",
    "    # multi-layer perceptron\n",
    "    for i in range(num_mlp_layers-1):\n",
    "        new_h = Dense(hidden_size,\n",
    "                      kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "                      bias_initializer=\"zeros\",\n",
    "                      kernel_regularizer=keras.regularizers.l2(l2_reg))(h)\n",
    "        # add batch normalization layer\n",
    "        if batch_norm:\n",
    "            new_h = BatchNormalization()(new_h)\n",
    "        # add residual connection\n",
    "        if i == 0:\n",
    "            h = new_h\n",
    "        else:\n",
    "            h = Add()([h, new_h])\n",
    "        # add activation\n",
    "        h = Activation(activation)(h)\n",
    "    y = Dense(output_size,\n",
    "              activation=\"softmax\",\n",
    "              kernel_initializer=keras.initializers.he_normal(seed=0),\n",
    "              bias_initializer=\"zeros\")(h)\n",
    "    \n",
    "    # set the loss, the optimizer, and the metric\n",
    "    if optimizer == \"SGD\":\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == \"Adam\":\n",
    "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    model = Model(x, y)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1b47d4",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f680a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'final_dataset_formatted.csv'\n",
    "TEST_FILENAME = 'final_dataset_formatted_test.csv'\n",
    "\n",
    "# load data\n",
    "df = load_data(FILENAME)\n",
    "df_test = load_data(TEST_FILENAME)\n",
    "\n",
    "# labels\n",
    "labels = ['CC', 'NC', 'PW', 'HC', 'PL', 'CR', 'CG', 'BE', 'N']\n",
    "num_labels = 9\n",
    "\n",
    "# split data\n",
    "df_train, df_val = split_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2698f0",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f655506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text and labels\n",
    "train_texts = df_train.iloc[:, 0]\n",
    "train_labels = df_train.iloc[:, 1]\n",
    "valid_texts = df_val.iloc[:, 0]\n",
    "valid_labels = df_val.iloc[:, 1]\n",
    "test_texts = df_test.iloc[:, 0]\n",
    "test_labels = df_test.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67da9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 3645\n",
      "valid size: 405\n",
      "test size: 450\n"
     ]
    }
   ],
   "source": [
    "# get train, validation, and test dataset size\n",
    "train_size = len(train_texts)\n",
    "valid_size = len(valid_texts)\n",
    "test_size = len(test_texts)\n",
    "\n",
    "print(f'train size: {train_size}')\n",
    "print(f'valid size: {valid_size}')\n",
    "print(f'test size: {test_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23854a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of features: 2465\n"
     ]
    }
   ],
   "source": [
    "# extract features\n",
    "min_freq = 3\n",
    "\n",
    "train_tokens = [tokenize(text) for text in train_texts]\n",
    "valid_tokens = [tokenize(text) for text in valid_texts]\n",
    "test_tokens = [tokenize(text) for text in test_texts]\n",
    "\n",
    "train_stemmed = [stem(tokens) for tokens in train_tokens]\n",
    "valid_stemmed = [stem(tokens) for tokens in valid_tokens]\n",
    "test_stemmed = [stem(tokens) for tokens in test_tokens]\n",
    "\n",
    "train_feats = [filter_stopwords(tokens) for tokens in train_stemmed]\n",
    "valid_feats = [filter_stopwords(tokens) for tokens in valid_stemmed]\n",
    "test_feats = [filter_stopwords(tokens) for tokens in test_stemmed]\n",
    "\n",
    "# build a mapping from features to indices\n",
    "feats_dict = get_feats_dict(\n",
    "    chain.from_iterable(train_feats),\n",
    "    min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdcb621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75 # from EDA\n",
    "\n",
    "# build the feats_matrix\n",
    "# convert each example to a index vector, and then stack vectors as a matrix\n",
    "train_feats_matrix = np.vstack(\n",
    "    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n",
    "valid_feats_matrix = np.vstack(\n",
    "    [get_index_vector(f, feats_dict, max_len) for f in valid_feats])\n",
    "test_feats_matrix = np.vstack(\n",
    "    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n",
    "\n",
    "# convert each label to a ont-hot vector, and then stack vectors as a matrix\n",
    "train_label_matrix = keras.utils.to_categorical(train_labels, num_classes=num_labels)\n",
    "valid_label_matrix = keras.utils.to_categorical(valid_labels, num_classes=num_labels)\n",
    "test_label_matrix = tf.keras.utils.to_categorical(test_labels, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72362660",
   "metadata": {},
   "source": [
    "## Fine-Tune Model  \n",
    "  \n",
    "optimizer  \n",
    "embedding_size    \n",
    "hidden_size  \n",
    "kernel_sizes   \n",
    "num_filters  \n",
    "num_mlp_layers  \n",
    "strides  \n",
    "dropout_rate  \n",
    "l2_reg  \n",
    "batch_norm  \n",
    "learning_rate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "292ed96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6648f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator for saving models' weights\n",
    "count = 0\n",
    "\n",
    "# initial settings\n",
    "epoch = 20\n",
    "batch_size = 100\n",
    "optimizer = 'SGD'\n",
    "embedding_size = 100\n",
    "hidden_size = 100\n",
    "kernel_sizes = [1, 2, 3, 4]\n",
    "num_filters = 100\n",
    "num_mlp_layers = 3\n",
    "strides = 1\n",
    "dropout_rate = 0.5\n",
    "l2_reg = 0.005\n",
    "batch_norm = True\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec964d72",
   "metadata": {},
   "source": [
    "### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1078c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1\n",
      "optimizer: SGD\n",
      "13/13 [==============================] - 1s 19ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8308\n",
      "----------------------------------------------------------------------------\n",
      "count: 2\n",
      "optimizer: RMSprop\n",
      "13/13 [==============================] - 8s 19ms/step\n",
      "accuracy: 0.8148\n",
      "macro_f1: 0.8159\n",
      "----------------------------------------------------------------------------\n",
      "count: 3\n",
      "optimizer: Adam\n",
      "13/13 [==============================] - 17s 29ms/step\n",
      "accuracy: 0.8198\n",
      "macro_f1: 0.8197\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "optimizer: SGD, accuracy: 0.8296296296296296, macro_f1: 0.8307689237655485\n"
     ]
    }
   ],
   "source": [
    "optimizer_list = ['SGD', 'RMSprop', 'Adam']\n",
    "best_optimizer = ''\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for optimizer in optimizer_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'optimizer: {optimizer}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_optimizer = optimizer\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'optimizer: {best_optimizer}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb6012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = best_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293df38",
   "metadata": {},
   "source": [
    "### embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c89bf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 4\n",
      "embedding_size: 50\n",
      "13/13 [==============================] - 7s 17ms/step\n",
      "accuracy: 0.8049\n",
      "macro_f1: 0.8065\n",
      "----------------------------------------------------------------------------\n",
      "count: 5\n",
      "embedding_size: 75\n",
      "13/13 [==============================] - 16s 22ms/step\n",
      "accuracy: 0.8074\n",
      "macro_f1: 0.8086\n",
      "----------------------------------------------------------------------------\n",
      "count: 6\n",
      "embedding_size: 100\n",
      "13/13 [==============================] - 13s 22ms/step\n",
      "accuracy: 0.8321\n",
      "macro_f1: 0.8338\n",
      "----------------------------------------------------------------------------\n",
      "count: 7\n",
      "embedding_size: 128\n",
      "13/13 [==============================] - 13s 34ms/step\n",
      "accuracy: 0.8123\n",
      "macro_f1: 0.8155\n",
      "----------------------------------------------------------------------------\n",
      "count: 8\n",
      "embedding_size: 256\n",
      "13/13 [==============================] - 14s 51ms/step\n",
      "accuracy: 0.8173\n",
      "macro_f1: 0.8176\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "embedding_size: 100, accuracy: 0.8320987654320988, macro_f1: 0.833784929289487\n"
     ]
    }
   ],
   "source": [
    "embedding_size_list = [50, 75, 100, 128, 256]\n",
    "best_embedding_size = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for embedding_size in embedding_size_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'embedding_size: {embedding_size}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_embedding_size = embedding_size\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'embedding_size: {best_embedding_size}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96020e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = best_embedding_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f2968",
   "metadata": {},
   "source": [
    "### hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "096a515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 9\n",
      "hidden_size: 50\n",
      "13/13 [==============================] - 8s 23ms/step\n",
      "accuracy: 0.8025\n",
      "macro_f1: 0.8052\n",
      "----------------------------------------------------------------------------\n",
      "count: 10\n",
      "hidden_size: 75\n",
      "13/13 [==============================] - 4s 24ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8313\n",
      "----------------------------------------------------------------------------\n",
      "count: 11\n",
      "hidden_size: 100\n",
      "13/13 [==============================] - 12s 25ms/step\n",
      "accuracy: 0.8222\n",
      "macro_f1: 0.8241\n",
      "----------------------------------------------------------------------------\n",
      "count: 12\n",
      "hidden_size: 128\n",
      "13/13 [==============================] - 2s 25ms/step\n",
      "accuracy: 0.8123\n",
      "macro_f1: 0.8134\n",
      "----------------------------------------------------------------------------\n",
      "count: 13\n",
      "hidden_size: 256\n",
      "13/13 [==============================] - 3s 24ms/step\n",
      "accuracy: 0.7778\n",
      "macro_f1: 0.7833\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "hidden_size: 75, accuracy: 0.8296296296296296, macro_f1: 0.8313287999094097\n"
     ]
    }
   ],
   "source": [
    "hidden_size_list = [50, 75, 100, 128, 256]\n",
    "best_hidden_size = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for hidden_size in hidden_size_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'hidden_size: {hidden_size}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_hidden_size = hidden_size\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'hidden_size: {best_hidden_size}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b68ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = best_hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad25091",
   "metadata": {},
   "source": [
    "### kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed648095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 14\n",
      "kernel_size: [1]\n",
      "13/13 [==============================] - 3s 20ms/step\n",
      "accuracy: 0.8247\n",
      "macro_f1: 0.8251\n",
      "----------------------------------------------------------------------------\n",
      "count: 15\n",
      "kernel_size: [1, 2]\n",
      "13/13 [==============================] - 3s 24ms/step\n",
      "accuracy: 0.8247\n",
      "macro_f1: 0.8254\n",
      "----------------------------------------------------------------------------\n",
      "count: 16\n",
      "kernel_size: [1, 2, 3]\n",
      "13/13 [==============================] - 2s 22ms/step\n",
      "accuracy: 0.8198\n",
      "macro_f1: 0.8219\n",
      "----------------------------------------------------------------------------\n",
      "count: 17\n",
      "kernel_size: [1, 2, 3, 4]\n",
      "13/13 [==============================] - 4s 20ms/step\n",
      "accuracy: 0.8272\n",
      "macro_f1: 0.8277\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "kernel_size: [1, 2, 3, 4], accuracy: 0.8271604938271605, macro_f1: 0.827652249795631\n"
     ]
    }
   ],
   "source": [
    "kernel_size_list = [[1], [1, 2], [1, 2, 3], [1, 2, 3, 4]]\n",
    "best_kernel_size = []\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for kernel_size in kernel_size_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'kernel_size: {kernel_size}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_kernel_size = kernel_size\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'kernel_size: {best_kernel_size}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8f962bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = best_kernel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913f4c3",
   "metadata": {},
   "source": [
    "### num_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed24e1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 18\n",
      "num_filters: 25\n",
      "13/13 [==============================] - 8s 20ms/step\n",
      "accuracy: 0.7580\n",
      "macro_f1: 0.7616\n",
      "----------------------------------------------------------------------------\n",
      "count: 19\n",
      "num_filters: 50\n",
      "13/13 [==============================] - 3s 7ms/step\n",
      "accuracy: 0.8148\n",
      "macro_f1: 0.8155\n",
      "----------------------------------------------------------------------------\n",
      "count: 20\n",
      "num_filters: 100\n",
      "13/13 [==============================] - 1s 7ms/step\n",
      "accuracy: 0.8222\n",
      "macro_f1: 0.8245\n",
      "----------------------------------------------------------------------------\n",
      "count: 21\n",
      "num_filters: 150\n",
      "13/13 [==============================] - 1s 16ms/step\n",
      "accuracy: 0.8148\n",
      "macro_f1: 0.8161\n",
      "----------------------------------------------------------------------------\n",
      "count: 22\n",
      "num_filters: 200\n",
      "13/13 [==============================] - 1s 14ms/step\n",
      "accuracy: 0.8222\n",
      "macro_f1: 0.8221\n",
      "----------------------------------------------------------------------------\n",
      "count: 23\n",
      "num_filters: 256\n",
      "13/13 [==============================] - 1s 22ms/step\n",
      "accuracy: 0.8272\n",
      "macro_f1: 0.8286\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "num_filters: 256, accuracy: 0.8271604938271605, macro_f1: 0.8285827329380219\n"
     ]
    }
   ],
   "source": [
    "num_filters_list = [25, 50, 100, 150, 200, 256]\n",
    "best_num_filters = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for num_filters in num_filters_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'num_filters: {num_filters}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_num_filters = num_filters\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'num_filters: {best_num_filters}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1f85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = best_num_filters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80d808",
   "metadata": {},
   "source": [
    "### num_mlp_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed94b012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 24\n",
      "num_mlp_layers: 1\n",
      "13/13 [==============================] - 1s 34ms/step\n",
      "accuracy: 0.7901\n",
      "macro_f1: 0.7879\n",
      "----------------------------------------------------------------------------\n",
      "count: 25\n",
      "num_mlp_layers: 2\n",
      "13/13 [==============================] - 1s 21ms/step\n",
      "accuracy: 0.8469\n",
      "macro_f1: 0.8470\n",
      "----------------------------------------------------------------------------\n",
      "count: 26\n",
      "num_mlp_layers: 3\n",
      "13/13 [==============================] - 1s 20ms/step\n",
      "accuracy: 0.8222\n",
      "macro_f1: 0.8234\n",
      "----------------------------------------------------------------------------\n",
      "count: 27\n",
      "num_mlp_layers: 4\n",
      "13/13 [==============================] - 1s 28ms/step\n",
      "accuracy: 0.8247\n",
      "macro_f1: 0.8246\n",
      "----------------------------------------------------------------------------\n",
      "count: 28\n",
      "num_mlp_layers: 5\n",
      "13/13 [==============================] - 2s 27ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8309\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "num_mlp_layers: 2, accuracy: 0.8469135802469135, macro_f1: 0.8470305701571346\n"
     ]
    }
   ],
   "source": [
    "num_mlp_layers_list = [1, 2, 3, 4, 5]\n",
    "best_num_mlp_layers = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for num_mlp_layers in num_mlp_layers_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'num_mlp_layers: {num_mlp_layers}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_num_mlp_layers = num_mlp_layers\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'num_mlp_layers: {best_num_mlp_layers}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90b56a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mlp_layers = best_num_mlp_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803ed3db",
   "metadata": {},
   "source": [
    "### strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18d3f6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 29\n",
      "strides: 1\n",
      "13/13 [==============================] - 1s 16ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8310\n",
      "----------------------------------------------------------------------------\n",
      "count: 30\n",
      "strides: 2\n",
      "13/13 [==============================] - 2s 34ms/step\n",
      "accuracy: 0.8247\n",
      "macro_f1: 0.8246\n",
      "----------------------------------------------------------------------------\n",
      "count: 31\n",
      "strides: 3\n",
      "13/13 [==============================] - 1s 20ms/step\n",
      "accuracy: 0.8025\n",
      "macro_f1: 0.8038\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "strides: 1, accuracy: 0.8296296296296296, macro_f1: 0.830995387119247\n"
     ]
    }
   ],
   "source": [
    "strides_list = [1, 2, 3]\n",
    "best_strides = ''\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for strides in strides_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'strides: {strides}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_strides = strides\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'strides: {best_strides}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb88c125",
   "metadata": {},
   "outputs": [],
   "source": [
    "strides = best_strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e795c",
   "metadata": {},
   "source": [
    "### dropout_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dc8024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 32\n",
      "dropout_rate: 0.1\n",
      "13/13 [==============================] - 1s 29ms/step\n",
      "accuracy: 0.8346\n",
      "macro_f1: 0.8354\n",
      "----------------------------------------------------------------------------\n",
      "count: 33\n",
      "dropout_rate: 0.3\n",
      "13/13 [==============================] - 1s 38ms/step\n",
      "accuracy: 0.8198\n",
      "macro_f1: 0.8197\n",
      "----------------------------------------------------------------------------\n",
      "count: 34\n",
      "dropout_rate: 0.5\n",
      "13/13 [==============================] - 4s 61ms/step\n",
      "accuracy: 0.8247\n",
      "macro_f1: 0.8260\n",
      "----------------------------------------------------------------------------\n",
      "count: 35\n",
      "dropout_rate: 0.6\n",
      "13/13 [==============================] - 2s 41ms/step\n",
      "accuracy: 0.8370\n",
      "macro_f1: 0.8395\n",
      "----------------------------------------------------------------------------\n",
      "count: 36\n",
      "dropout_rate: 0.7\n",
      "13/13 [==============================] - 3s 41ms/step\n",
      "accuracy: 0.8420\n",
      "macro_f1: 0.8424\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "dropout_rate: 0.7, accuracy: 0.8419753086419753, macro_f1: 0.8423621650917963\n"
     ]
    }
   ],
   "source": [
    "dropout_rate_list = [0.1, 0.3, 0.5, 0.6, 0.7]\n",
    "best_dropout_rate = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for dropout_rate in dropout_rate_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'dropout_rate: {dropout_rate}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_dropout_rate = dropout_rate\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'dropout_rate: {best_dropout_rate}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a63e3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = best_dropout_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769e164",
   "metadata": {},
   "source": [
    "### l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb8666fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 37\n",
      "l2_reg: 0.001\n",
      "13/13 [==============================] - 5s 53ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8300\n",
      "----------------------------------------------------------------------------\n",
      "count: 38\n",
      "l2_reg: 0.005\n",
      "13/13 [==============================] - 2s 22ms/step\n",
      "accuracy: 0.8346\n",
      "macro_f1: 0.8347\n",
      "----------------------------------------------------------------------------\n",
      "count: 39\n",
      "l2_reg: 0.01\n",
      "13/13 [==============================] - 2s 34ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8303\n",
      "----------------------------------------------------------------------------\n",
      "count: 40\n",
      "l2_reg: 0.1\n",
      "13/13 [==============================] - 1s 32ms/step\n",
      "accuracy: 0.8395\n",
      "macro_f1: 0.8390\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "l2_reg: 0.1, accuracy: 0.8395061728395061, macro_f1: 0.8390493350258094\n"
     ]
    }
   ],
   "source": [
    "l2_reg_list = [0.001, 0.005, 0.01, 0.1]\n",
    "best_l2_reg = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for l2_reg in l2_reg_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'l2_reg: {l2_reg}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_l2_reg = l2_reg\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'l2_reg: {best_l2_reg}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c655ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = best_l2_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9305bad",
   "metadata": {},
   "source": [
    "### batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39ad5475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 41\n",
      "batch_norm: True\n",
      "13/13 [==============================] - 1s 26ms/step\n",
      "accuracy: 0.8123\n",
      "macro_f1: 0.8123\n",
      "----------------------------------------------------------------------------\n",
      "count: 42\n",
      "batch_norm: False\n",
      "13/13 [==============================] - 1s 18ms/step\n",
      "accuracy: 0.2272\n",
      "macro_f1: 0.1484\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "batch_norm: True, accuracy: 0.8123456790123457, macro_f1: 0.8123124347433277\n"
     ]
    }
   ],
   "source": [
    "batch_norm_list = [True, False]\n",
    "best_batch_norm = False\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for batch_norm in batch_norm_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'batch_norm: {batch_norm}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_batch_norm = batch_norm\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'batch_norm: {best_batch_norm}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "feb29903",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = best_batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af01065",
   "metadata": {},
   "source": [
    "### learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5795afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 43\n",
      "learning_rate: 0.0001\n",
      "13/13 [==============================] - 1s 16ms/step\n",
      "accuracy: 0.1235\n",
      "macro_f1: 0.0761\n",
      "----------------------------------------------------------------------------\n",
      "count: 44\n",
      "learning_rate: 0.001\n",
      "13/13 [==============================] - 1s 28ms/step\n",
      "accuracy: 0.1407\n",
      "macro_f1: 0.0999\n",
      "----------------------------------------------------------------------------\n",
      "count: 45\n",
      "learning_rate: 0.01\n",
      "13/13 [==============================] - 1s 25ms/step\n",
      "accuracy: 0.7062\n",
      "macro_f1: 0.7243\n",
      "----------------------------------------------------------------------------\n",
      "count: 46\n",
      "learning_rate: 0.1\n",
      "13/13 [==============================] - 1s 23ms/step\n",
      "accuracy: 0.8296\n",
      "macro_f1: 0.8292\n",
      "----------------------------------------------------------------------------\n",
      "Best model:\n",
      "learning_rate: 0.1, accuracy: 0.8296296296296296, macro_f1: 0.8292414238255478\n"
     ]
    }
   ],
   "source": [
    "learning_rate_list = [0.0001, 0.001, 0.01, 0.1]\n",
    "best_learning_rate = 0\n",
    "best_acc = 0\n",
    "best_f1 = 0\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "\n",
    "    count += 1\n",
    "\n",
    "    model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"),\n",
    "        monitor=\"val_accuracy\",\n",
    "        verbose=0,\n",
    "        save_best_only=True)\n",
    "\n",
    "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_tune{count}.hdf5\"))\n",
    "\n",
    "    print(f'count: {count}')\n",
    "    print(f'learning_rate: {learning_rate}')\n",
    "\n",
    "    # evaluation\n",
    "    # generate prediction and format\n",
    "    y_pred = model.predict(valid_feats_matrix)\n",
    "    y_pred = [np.argmax(row) for row in y_pred]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    # evaluate performance\n",
    "    acc = accuracy_score(valid_labels, y_pred)\n",
    "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "    print(f'accuracy: {acc:.4f}')\n",
    "    print(f'macro_f1: {f1:.4f}')\n",
    "\n",
    "    # save best model\n",
    "    if f1 > best_f1:\n",
    "        best_learning_rate = learning_rate\n",
    "        best_acc = acc\n",
    "        best_f1 = f1\n",
    "    \n",
    "    print('----------------------------------------------------------------------------')\n",
    "\n",
    "print('Best model:')\n",
    "print(f'learning_rate: {best_learning_rate}, accuracy: {best_acc}, macro_f1: {best_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef5c426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = best_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8cac4",
   "metadata": {},
   "source": [
    "## Final CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4eae3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model obtained before\n",
    "epoch = 35\n",
    "batch_size = 100\n",
    "optimizer = 'SGD'\n",
    "embedding_size = 256\n",
    "hidden_size = 100\n",
    "kernel_sizes = [1, 2]\n",
    "num_filters = 256\n",
    "num_mlp_layers = 4\n",
    "strides = 1\n",
    "dropout_rate = 0.5\n",
    "l2_reg = 0.005\n",
    "batch_norm = True\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "914863e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "37/37 [==============================] - 14s 245ms/step - loss: 5.1881 - accuracy: 0.2335 - precision_46: 0.4208 - recall_46: 0.0875 - val_loss: 4.9959 - val_accuracy: 0.1111 - val_precision_46: 0.0000e+00 - val_recall_46: 0.0000e+00\n",
      "Epoch 2/35\n",
      "37/37 [==============================] - 8s 207ms/step - loss: 4.1441 - accuracy: 0.5147 - precision_46: 0.7849 - recall_46: 0.3273 - val_loss: 4.6813 - val_accuracy: 0.2321 - val_precision_46: 0.0000e+00 - val_recall_46: 0.0000e+00\n",
      "Epoch 3/35\n",
      "37/37 [==============================] - 8s 205ms/step - loss: 3.6304 - accuracy: 0.6417 - precision_46: 0.8282 - recall_46: 0.4919 - val_loss: 4.4721 - val_accuracy: 0.2296 - val_precision_46: 0.0000e+00 - val_recall_46: 0.0000e+00\n",
      "Epoch 4/35\n",
      "37/37 [==============================] - 8s 208ms/step - loss: 3.2454 - accuracy: 0.7012 - precision_46: 0.8403 - recall_46: 0.5934 - val_loss: 4.2060 - val_accuracy: 0.3111 - val_precision_46: 0.0000e+00 - val_recall_46: 0.0000e+00\n",
      "Epoch 5/35\n",
      "37/37 [==============================] - 8s 205ms/step - loss: 2.9399 - accuracy: 0.7627 - precision_46: 0.8635 - recall_46: 0.6785 - val_loss: 4.1598 - val_accuracy: 0.1877 - val_precision_46: 0.9000 - val_recall_46: 0.0444\n",
      "Epoch 6/35\n",
      "37/37 [==============================] - 8s 206ms/step - loss: 2.6815 - accuracy: 0.7926 - precision_46: 0.8636 - recall_46: 0.7191 - val_loss: 3.8429 - val_accuracy: 0.2494 - val_precision_46: 0.7000 - val_recall_46: 0.0691\n",
      "Epoch 7/35\n",
      "37/37 [==============================] - 8s 208ms/step - loss: 2.4414 - accuracy: 0.8233 - precision_46: 0.8809 - recall_46: 0.7652 - val_loss: 3.7170 - val_accuracy: 0.2395 - val_precision_46: 0.3673 - val_recall_46: 0.1333\n",
      "Epoch 8/35\n",
      "37/37 [==============================] - 8s 210ms/step - loss: 2.2541 - accuracy: 0.8373 - precision_46: 0.8830 - recall_46: 0.7973 - val_loss: 3.3340 - val_accuracy: 0.3926 - val_precision_46: 0.6846 - val_recall_46: 0.2198\n",
      "Epoch 9/35\n",
      "37/37 [==============================] - 8s 205ms/step - loss: 2.0659 - accuracy: 0.8562 - precision_46: 0.8994 - recall_46: 0.8266 - val_loss: 3.2364 - val_accuracy: 0.3654 - val_precision_46: 0.4756 - val_recall_46: 0.2642\n",
      "Epoch 10/35\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 1.8944 - accuracy: 0.8765 - precision_46: 0.9087 - recall_46: 0.8466 - val_loss: 2.8288 - val_accuracy: 0.5333 - val_precision_46: 0.5765 - val_recall_46: 0.4000\n",
      "Epoch 11/35\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 1.7451 - accuracy: 0.8938 - precision_46: 0.9173 - recall_46: 0.8700 - val_loss: 2.5505 - val_accuracy: 0.6000 - val_precision_46: 0.6585 - val_recall_46: 0.5333\n",
      "Epoch 12/35\n",
      "37/37 [==============================] - 8s 208ms/step - loss: 1.6110 - accuracy: 0.9056 - precision_46: 0.9260 - recall_46: 0.8886 - val_loss: 2.2575 - val_accuracy: 0.6914 - val_precision_46: 0.7493 - val_recall_46: 0.6494\n",
      "Epoch 13/35\n",
      "37/37 [==============================] - 8s 210ms/step - loss: 1.5218 - accuracy: 0.9062 - precision_46: 0.9234 - recall_46: 0.8859 - val_loss: 1.9679 - val_accuracy: 0.7580 - val_precision_46: 0.8129 - val_recall_46: 0.6864\n",
      "Epoch 14/35\n",
      "37/37 [==============================] - 8s 211ms/step - loss: 1.3812 - accuracy: 0.9218 - precision_46: 0.9382 - recall_46: 0.9037 - val_loss: 1.8702 - val_accuracy: 0.7654 - val_precision_46: 0.8324 - val_recall_46: 0.7235\n",
      "Epoch 15/35\n",
      "37/37 [==============================] - 8s 210ms/step - loss: 1.2963 - accuracy: 0.9284 - precision_46: 0.9406 - recall_46: 0.9163 - val_loss: 1.7990 - val_accuracy: 0.7951 - val_precision_46: 0.8213 - val_recall_46: 0.7605\n",
      "Epoch 16/35\n",
      "37/37 [==============================] - 8s 217ms/step - loss: 1.1998 - accuracy: 0.9328 - precision_46: 0.9416 - recall_46: 0.9248 - val_loss: 1.7128 - val_accuracy: 0.7975 - val_precision_46: 0.8386 - val_recall_46: 0.7827\n",
      "Epoch 17/35\n",
      "37/37 [==============================] - 8s 213ms/step - loss: 1.1137 - accuracy: 0.9418 - precision_46: 0.9487 - recall_46: 0.9328 - val_loss: 1.6103 - val_accuracy: 0.8148 - val_precision_46: 0.8399 - val_recall_46: 0.7901\n",
      "Epoch 18/35\n",
      "37/37 [==============================] - 8s 208ms/step - loss: 1.0325 - accuracy: 0.9424 - precision_46: 0.9531 - recall_46: 0.9358 - val_loss: 1.6154 - val_accuracy: 0.8000 - val_precision_46: 0.8184 - val_recall_46: 0.7679\n",
      "Epoch 19/35\n",
      "37/37 [==============================] - 8s 208ms/step - loss: 0.9803 - accuracy: 0.9416 - precision_46: 0.9501 - recall_46: 0.9347 - val_loss: 1.5467 - val_accuracy: 0.8025 - val_precision_46: 0.8286 - val_recall_46: 0.7877\n",
      "Epoch 20/35\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 0.9033 - accuracy: 0.9509 - precision_46: 0.9593 - recall_46: 0.9443 - val_loss: 1.5394 - val_accuracy: 0.8222 - val_precision_46: 0.8406 - val_recall_46: 0.8074\n",
      "Epoch 21/35\n",
      "37/37 [==============================] - 8s 206ms/step - loss: 0.8631 - accuracy: 0.9473 - precision_46: 0.9546 - recall_46: 0.9407 - val_loss: 1.5165 - val_accuracy: 0.8148 - val_precision_46: 0.8316 - val_recall_46: 0.8049\n",
      "Epoch 22/35\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 0.7992 - accuracy: 0.9547 - precision_46: 0.9606 - recall_46: 0.9492 - val_loss: 1.4177 - val_accuracy: 0.8247 - val_precision_46: 0.8444 - val_recall_46: 0.8173\n",
      "Epoch 23/35\n",
      "37/37 [==============================] - 8s 210ms/step - loss: 0.7543 - accuracy: 0.9547 - precision_46: 0.9609 - recall_46: 0.9506 - val_loss: 1.4278 - val_accuracy: 0.8198 - val_precision_46: 0.8454 - val_recall_46: 0.8099\n",
      "Epoch 24/35\n",
      "37/37 [==============================] - 8s 213ms/step - loss: 0.7148 - accuracy: 0.9558 - precision_46: 0.9622 - recall_46: 0.9509 - val_loss: 1.3342 - val_accuracy: 0.8272 - val_precision_46: 0.8494 - val_recall_46: 0.8074\n",
      "Epoch 25/35\n",
      "37/37 [==============================] - 8s 212ms/step - loss: 0.6770 - accuracy: 0.9575 - precision_46: 0.9602 - recall_46: 0.9528 - val_loss: 1.2928 - val_accuracy: 0.8321 - val_precision_46: 0.8527 - val_recall_46: 0.8148\n",
      "Epoch 26/35\n",
      "37/37 [==============================] - 8s 206ms/step - loss: 0.6160 - accuracy: 0.9638 - precision_46: 0.9672 - recall_46: 0.9616 - val_loss: 1.2907 - val_accuracy: 0.8148 - val_precision_46: 0.8410 - val_recall_46: 0.8099\n",
      "Epoch 27/35\n",
      "37/37 [==============================] - 8s 205ms/step - loss: 0.5834 - accuracy: 0.9632 - precision_46: 0.9677 - recall_46: 0.9608 - val_loss: 1.2388 - val_accuracy: 0.8148 - val_precision_46: 0.8380 - val_recall_46: 0.8049\n",
      "Epoch 28/35\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 0.5634 - accuracy: 0.9586 - precision_46: 0.9640 - recall_46: 0.9545 - val_loss: 1.2420 - val_accuracy: 0.8346 - val_precision_46: 0.8495 - val_recall_46: 0.8222\n",
      "Epoch 29/35\n",
      "37/37 [==============================] - 8s 209ms/step - loss: 0.5068 - accuracy: 0.9701 - precision_46: 0.9735 - recall_46: 0.9679 - val_loss: 1.1955 - val_accuracy: 0.8370 - val_precision_46: 0.8473 - val_recall_46: 0.8222\n",
      "Epoch 30/35\n",
      "37/37 [==============================] - 7s 202ms/step - loss: 0.4861 - accuracy: 0.9695 - precision_46: 0.9719 - recall_46: 0.9679 - val_loss: 1.2340 - val_accuracy: 0.8346 - val_precision_46: 0.8396 - val_recall_46: 0.8272\n",
      "Epoch 31/35\n",
      "37/37 [==============================] - 7s 196ms/step - loss: 0.4657 - accuracy: 0.9684 - precision_46: 0.9702 - recall_46: 0.9652 - val_loss: 1.2190 - val_accuracy: 0.8272 - val_precision_46: 0.8401 - val_recall_46: 0.8173\n",
      "Epoch 32/35\n",
      "37/37 [==============================] - 8s 203ms/step - loss: 0.4323 - accuracy: 0.9756 - precision_46: 0.9777 - recall_46: 0.9737 - val_loss: 1.3088 - val_accuracy: 0.8148 - val_precision_46: 0.8321 - val_recall_46: 0.8074\n",
      "Epoch 33/35\n",
      "37/37 [==============================] - 8s 219ms/step - loss: 0.4352 - accuracy: 0.9665 - precision_46: 0.9705 - recall_46: 0.9641 - val_loss: 1.1563 - val_accuracy: 0.8346 - val_precision_46: 0.8417 - val_recall_46: 0.8272\n",
      "Epoch 34/35\n",
      "37/37 [==============================] - 8s 218ms/step - loss: 0.4216 - accuracy: 0.9652 - precision_46: 0.9702 - recall_46: 0.9632 - val_loss: 1.1688 - val_accuracy: 0.8370 - val_precision_46: 0.8467 - val_recall_46: 0.8321\n",
      "Epoch 35/35\n",
      "37/37 [==============================] - 9s 238ms/step - loss: 0.3800 - accuracy: 0.9728 - precision_46: 0.9760 - recall_46: 0.9709 - val_loss: 1.1735 - val_accuracy: 0.8346 - val_precision_46: 0.8421 - val_recall_46: 0.8296\n",
      "13/13 [==============================] - 1s 21ms/step\n",
      "accuracy: 0.8370\n",
      "macro_f1: 0.8378\n"
     ]
    }
   ],
   "source": [
    "model = build_CNN(input_length=max_len, \n",
    "                      vocab_size=len(feats_dict), \n",
    "                      embedding_size=embedding_size, \n",
    "                      hidden_size=hidden_size,\n",
    "                      output_size=num_labels,\n",
    "                      kernel_sizes=kernel_sizes, \n",
    "                      num_filters=num_filters, \n",
    "                      num_mlp_layers=num_mlp_layers, \n",
    "                      strides=strides, \n",
    "                      dropout_rate=dropout_rate, \n",
    "                      batch_norm=batch_norm,\n",
    "                      l2_reg=l2_reg,\n",
    "                      optimizer=optimizer, \n",
    "                      learning_rate=learning_rate\n",
    "                     )\n",
    "\n",
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(\"models\", f\"weights_CNN_final.hdf5\"),\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
    "                    validation_data=(valid_feats_matrix, valid_label_matrix),\n",
    "                    epochs=epoch, batch_size=batch_size, verbose=1,\n",
    "                    callbacks=[checkpointer])\n",
    "\n",
    "model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_final.hdf5\"))\n",
    "\n",
    "# evaluation\n",
    "# generate prediction and format\n",
    "y_pred = model.predict(valid_feats_matrix)\n",
    "y_pred = [np.argmax(row) for row in y_pred]\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# evaluate performance\n",
    "acc = accuracy_score(valid_labels, y_pred)\n",
    "f1 = f1_score(valid_labels, y_pred, average='macro')\n",
    "print(f'accuracy: {acc:.4f}')\n",
    "print(f'macro_f1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08c4c8",
   "metadata": {},
   "source": [
    "## Final Model Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "904b319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(\"models\", f\"weights_CNN_final.hdf5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58951248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 10ms/step\n",
      "test accuracy: 0.8378\n",
      "test macro_f1: 0.8396\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.84      0.88        50\n",
      "          NC       0.94      0.88      0.91        50\n",
      "          PW       0.87      0.90      0.88        50\n",
      "          HC       0.65      0.80      0.71        50\n",
      "          PL       0.88      0.74      0.80        50\n",
      "          CR       0.82      0.74      0.78        50\n",
      "          CG       0.91      0.84      0.87        50\n",
      "          BE       0.90      0.88      0.89        50\n",
      "           N       0.74      0.92      0.82        50\n",
      "\n",
      "    accuracy                           0.84       450\n",
      "   macro avg       0.85      0.84      0.84       450\n",
      "weighted avg       0.85      0.84      0.84       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate prediction and format\n",
    "y_pred = model.predict(test_feats_matrix)\n",
    "y_pred = [np.argmax(row) for row in y_pred]\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# evaluate performance\n",
    "acc = accuracy_score(test_labels, y_pred)\n",
    "f1 = f1_score(test_labels, y_pred, average='macro')\n",
    "print(f'test accuracy: {acc:.4f}')\n",
    "print(f'test macro_f1: {f1:.4f}')\n",
    "print(classification_report(test_labels, y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85e4a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x14a38e8c4c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "cm = confusion_matrix(test_labels, y_pred , normalize='pred')\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808322d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
