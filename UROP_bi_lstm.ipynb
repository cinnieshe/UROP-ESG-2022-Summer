{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f5d7493e",
      "metadata": {
        "id": "f5d7493e"
      },
      "source": [
        "# Fine-Tune Bi-Directional LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009958f8",
      "metadata": {
        "id": "009958f8"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "58f8830d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58f8830d",
        "outputId": "60c67d91-c505-4b91-cc96-0dffcd06c75c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import os # store and load weight\n",
        "import pandas as pd # load data\n",
        "import nltk # text processing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import PorterStemmer # text processing\n",
        "from nltk.corpus import stopwords #text processing\n",
        "import numpy as np # one-hot vector\n",
        "import matplotlib.pyplot as plt # model analysis\n",
        "from itertools import chain # feature construction\n",
        "from collections import Counter # build feats-dict\n",
        "from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import keras\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Embedding, Dropout, BatchNormalization, Input, Add, Concatenate,\\\n",
        "    Bidirectional, SimpleRNN, LSTM, GRU\n",
        "\n",
        "\n",
        "stopwords = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e6bf78",
      "metadata": {
        "id": "08e6bf78"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cc4574c0",
      "metadata": {
        "id": "cc4574c0"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    Input: string filename\n",
        "    Output: a pandas dataframe for the whole dataset after droping missing values\n",
        "    Support google colab or local environments\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # local environment\n",
        "        df = pd.read_csv(filename)\n",
        "        df = df.dropna(subset=['sentence', 'label']) ## drop missing values\n",
        "        return df\n",
        "    except:\n",
        "        # google colab environment\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        \n",
        "        df = pd.read_csv('/content/drive/MyDrive/' + filename)\n",
        "        df = df.dropna(subset=['sentence', 'label']) ## drop missing values\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2b8210f7",
      "metadata": {
        "id": "2b8210f7"
      },
      "outputs": [],
      "source": [
        "def split_data(df):\n",
        "    \"\"\"\n",
        "    Input: pandas dataframe\n",
        "    Output: training dataframe (81%), validation dataframe (9%), test dataframe (10%)\n",
        "    \"\"\"\n",
        "    df_train, df_val = train_test_split(df, stratify=df['label'],test_size=0.1, random_state=42)\n",
        "    \n",
        "    return df_train, df_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b1e2f6ea",
      "metadata": {
        "id": "b1e2f6ea"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"\n",
        "    :param text: a doc with multiple sentences, type: str\n",
        "    return a word list, type: list\n",
        "    e.g.\n",
        "    Input: 'Text mining is to identify useful information.'\n",
        "    Output: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    \"\"\"\n",
        "    return nltk.word_tokenize(text)\n",
        "\n",
        "def stem(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of stemmed words, type: list\n",
        "    e.g.\n",
        "    Input: ['Text', 'mining', 'is', 'to', 'identify', 'useful', 'information', '.']\n",
        "    Output: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "\n",
        "    return [ps.stem(token) for token in tokens]\n",
        "\n",
        "def n_gram(tokens, n=1):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    :param n: the corresponding n-gram, type: int\n",
        "    return a list of n-gram tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.'], 2\n",
        "    Output: ['text mine', 'mine is', 'is to', 'to identifi', 'identifi use', 'use inform', 'inform .']\n",
        "    \"\"\"\n",
        "    if n == 1:\n",
        "        return tokens\n",
        "    else:\n",
        "        results = list()\n",
        "        for i in range(len(tokens)-n+1):\n",
        "            # tokens[i:i+n] will return a sublist from i th to i+n th (i+n th is not included)\n",
        "            results.append(\" \".join(tokens[i:i+n]))\n",
        "        return results\n",
        "    \n",
        "def filter_stopwords(tokens):\n",
        "    \"\"\"\n",
        "    :param tokens: a list of tokens, type: list\n",
        "    return a list of filtered tokens, type: list\n",
        "    e.g.\n",
        "    Input: ['text', 'mine', 'is', 'to', 'identifi', 'use', 'inform', '.']\n",
        "    Output: ['text', 'mine', 'identifi', 'use', 'inform', '.']\n",
        "    \"\"\"\n",
        "    return [token for token in tokens if token not in stopwords and not token.isnumeric()]\n",
        "\n",
        "def get_feats_dict(feats, min_freq=-1, max_freq=-1, max_size=-1):\n",
        "    \"\"\"\n",
        "    :param data: a list of features, type: list(list)\n",
        "    :param min_freq: the lowest fequency that the fequency of a feature smaller than it will be filtered out, type: int\n",
        "    :param max_freq: the highest fequency that the fequency of a feature larger than it will be filtered out, type: int\n",
        "    :param max_size: the max size of feature dict, type: int\n",
        "    return a feature dict that maps features to indices, sorted by frequencies\n",
        "    # Counter document: https://docs.python.org/3.6/library/collections.html#collections.Counter\n",
        "    \"\"\"\n",
        "    # count all features\n",
        "    feat_cnt = Counter(feats) # [\"text\", \"text\", \"mine\"] --> {\"text\": 2, \"mine\": 1}\n",
        "    if max_size > 0 and min_freq == -1 and max_freq == -1:\n",
        "        valid_feats = [f for f, cnt in feat_cnt.most_common(max_size)]\n",
        "    else:\n",
        "        valid_feats = list()\n",
        "        for f, cnt in feat_cnt.most_common():\n",
        "            if (min_freq == -1 or cnt >= min_freq) and \\\n",
        "                (max_freq == -1 or cnt <= max_freq):\n",
        "                valid_feats.append(f)\n",
        "    if max_size > 0 and len(valid_feats) > max_size:\n",
        "        valid_feats = valid_feats[:max_size]        \n",
        "    print(\"Size of features:\", len(valid_feats))\n",
        "    \n",
        "    # build a mapping from features to indices\n",
        "    feats_dict = dict(zip(valid_feats, range(len(valid_feats))))\n",
        "    return feats_dict\n",
        "\n",
        "def get_onehot_vector(feats, feats_dict):\n",
        "    \"\"\"\n",
        "    :param feats: a list of features, type: list\n",
        "    :param feats_dict: a dict from features to indices, type: dict\n",
        "    return a feature vector,\n",
        "    \"\"\"\n",
        "    # initialize the vector as all zeros\n",
        "    vector = np.zeros(len(feats_dict), dtype=np.float)\n",
        "    for f in feats:\n",
        "        # get the feature index, return -1 if the feature is not existed\n",
        "        f_idx = feats_dict.get(f, -1)\n",
        "        if f_idx != -1:\n",
        "            # set the corresponding element as 1\n",
        "            vector[f_idx] = 1\n",
        "    return vector\n",
        "\n",
        "# Get index vector\n",
        "def get_index_vector(feats, feats_dict, max_len):\n",
        "    \"\"\"\n",
        "    :param feats: a list of features, type: list\n",
        "    :param feats_dict: a dict from features to indices, type: dict\n",
        "    :param feats: a list of features, type: list\n",
        "    return a feature vector,\n",
        "    \"\"\"\n",
        "    # initialize the vector as all zeros\n",
        "    vector = np.zeros(max_len, dtype=np.int64)\n",
        "    for i, f in enumerate(feats):\n",
        "        if i == max_len:\n",
        "            break\n",
        "        # get the feature index, return 1 (<unk>) if the feature is not existed\n",
        "        try:\n",
        "            vector[i] = feats_dict[f]\n",
        "        except KeyError:\n",
        "            vector[i] = 1\n",
        "    return vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ba2e5264",
      "metadata": {
        "id": "ba2e5264"
      },
      "outputs": [],
      "source": [
        "def build_RNN(input_length, vocab_size, embedding_size,\n",
        "              hidden_size, output_size,\n",
        "              num_rnn_layers, num_mlp_layers,\n",
        "              rnn_type=\"lstm\",\n",
        "              bidirectional=False,\n",
        "              embedding_matrix=None,\n",
        "              activation=\"tanh\",\n",
        "              dropout_rate=0.0,\n",
        "              batch_norm=False,\n",
        "              l2_reg=0.0,\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              optimizer=\"Adam\",\n",
        "              learning_rate=0.001,\n",
        "              metric=\"accuracy\"):\n",
        "\n",
        "    x = Input(shape=(input_length,))\n",
        "    \n",
        "    ################################\n",
        "    ###### Word Representation #####\n",
        "    ################################\n",
        "    # word representation layer\n",
        "    if embedding_matrix is not None:\n",
        "        emb = Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_size,\n",
        "                        input_length=input_length,\n",
        "                        embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "                        trainable=False)(x)\n",
        "    else:\n",
        "        emb = Embedding(input_dim=vocab_size,\n",
        "                        output_dim=embedding_size,\n",
        "                        input_length=input_length,\n",
        "                        embeddings_initializer=keras.initializers.TruncatedNormal(mean=0.0, stddev=0.1, seed=0))(x)\n",
        "    \n",
        "    ################################\n",
        "    ####### Recurrent Layers #######\n",
        "    ################################\n",
        "    # recurrent layers\n",
        "    if rnn_type == \"rnn\":\n",
        "        fn = SimpleRNN\n",
        "    elif rnn_type == \"lstm\":\n",
        "        fn = LSTM\n",
        "    elif rnn_type == \"gru\":\n",
        "        fn = GRU\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    h = emb\n",
        "    for i in range(num_rnn_layers):\n",
        "        is_last = (i == num_rnn_layers-1)\n",
        "        if bidirectional:\n",
        "            h = Bidirectional(fn(hidden_size,\n",
        "                                 kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n",
        "                                 recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n",
        "                                 return_sequences=not is_last))(h)\n",
        "        else:\n",
        "            h = fn(hidden_size,\n",
        "                   kernel_initializer=keras.initializers.glorot_uniform(seed=0),\n",
        "                   recurrent_initializer=keras.initializers.Orthogonal(gain=1.0, seed=0),\n",
        "                   return_sequences=not is_last)(h)\n",
        "        h = Dropout(dropout_rate, seed=0)(h)\n",
        "    \n",
        "    ################################\n",
        "    #### Fully Connected Layers ####\n",
        "    ################################\n",
        "    # multi-layer perceptron\n",
        "    for i in range(num_mlp_layers-1):\n",
        "        new_h = Dense(hidden_size,\n",
        "                      kernel_initializer=keras.initializers.he_normal(seed=0),\n",
        "                      bias_initializer=\"zeros\",\n",
        "                      kernel_regularizer=keras.regularizers.l2(l2_reg))(h)\n",
        "        # add batch normalization layer\n",
        "        if batch_norm:\n",
        "            new_h = BatchNormalization()(new_h)\n",
        "        # add residual connection\n",
        "        if i == 0:\n",
        "            h = new_h\n",
        "        else:\n",
        "            h = Add()([h, new_h])\n",
        "        # add activation\n",
        "        h = Activation(activation)(h)\n",
        "    y = Dense(output_size,\n",
        "              activation=\"softmax\",\n",
        "              kernel_initializer=keras.initializers.he_normal(seed=0),\n",
        "              bias_initializer=\"zeros\")(h)\n",
        "    \n",
        "    # set the loss, the optimizer, and the metric\n",
        "    if optimizer == \"SGD\":\n",
        "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "    elif optimizer == \"RMSprop\":\n",
        "        optmizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
        "    elif optimizer == \"Adam\":\n",
        "        optmizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    model = Model(x, y)\n",
        "    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e808299",
      "metadata": {
        "id": "6e808299"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a800533e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a800533e",
        "outputId": "04ebde61-be44-4795-9c78-bd46d6051cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "FILENAME = 'final_dataset_formatted.csv'\n",
        "TEST_FILENAME = 'final_dataset_formatted_test.csv'\n",
        "\n",
        "# load data\n",
        "df = load_data(FILENAME)\n",
        "df_test = load_data(TEST_FILENAME)\n",
        "\n",
        "# labels\n",
        "labels = ['CC', 'NC', 'PW', 'HC', 'PL', 'CR', 'CG', 'BE', 'N']\n",
        "num_labels = 9\n",
        "\n",
        "# split data\n",
        "df_train, df_val = split_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3ef1538",
      "metadata": {
        "id": "e3ef1538"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9c1e5c86",
      "metadata": {
        "id": "9c1e5c86"
      },
      "outputs": [],
      "source": [
        "# split text and labels\n",
        "train_texts = df_train.iloc[:, 0]\n",
        "train_labels = df_train.iloc[:, 1]\n",
        "valid_texts = df_val.iloc[:, 0]\n",
        "valid_labels = df_val.iloc[:, 1]\n",
        "test_texts = df_test.iloc[:, 0]\n",
        "test_labels = df_test.iloc[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "06f680cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06f680cb",
        "outputId": "a8d9dfc0-b761-452a-8cb0-96899e7406f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train size: 3645\n",
            "valid size: 405\n",
            "test size: 450\n"
          ]
        }
      ],
      "source": [
        "# get train, validation, and test dataset size\n",
        "train_size = len(train_texts)\n",
        "valid_size = len(valid_texts)\n",
        "test_size = len(test_texts)\n",
        "\n",
        "print(f'train size: {train_size}')\n",
        "print(f'valid size: {valid_size}')\n",
        "print(f'test size: {test_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "22a28c0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22a28c0b",
        "outputId": "0a6f2a94-4fa6-45c9-ade5-33bcf8173c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of features: 2465\n"
          ]
        }
      ],
      "source": [
        "# extract features\n",
        "min_freq = 3\n",
        "\n",
        "train_tokens = [tokenize(text) for text in train_texts]\n",
        "valid_tokens = [tokenize(text) for text in valid_texts]\n",
        "test_tokens = [tokenize(text) for text in test_texts]\n",
        "\n",
        "train_stemmed = [stem(tokens) for tokens in train_tokens]\n",
        "valid_stemmed = [stem(tokens) for tokens in valid_tokens]\n",
        "test_stemmed = [stem(tokens) for tokens in test_tokens]\n",
        "\n",
        "train_feats = [filter_stopwords(tokens) for tokens in train_stemmed]\n",
        "valid_feats = [filter_stopwords(tokens) for tokens in valid_stemmed]\n",
        "test_feats = [filter_stopwords(tokens) for tokens in test_stemmed]\n",
        "\n",
        "# build a mapping from features to indices\n",
        "feats_dict = get_feats_dict(\n",
        "    chain.from_iterable(train_feats),\n",
        "    min_freq=min_freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "14716d41",
      "metadata": {
        "id": "14716d41"
      },
      "outputs": [],
      "source": [
        "max_len = 75 # from EDA\n",
        "\n",
        "# build the feats_matrix\n",
        "# convert each example to a index vector, and then stack vectors as a matrix\n",
        "train_feats_matrix = np.vstack(\n",
        "    [get_index_vector(f, feats_dict, max_len) for f in train_feats])\n",
        "valid_feats_matrix = np.vstack(\n",
        "    [get_index_vector(f, feats_dict, max_len) for f in valid_feats])\n",
        "test_feats_matrix = np.vstack(\n",
        "    [get_index_vector(f, feats_dict, max_len) for f in test_feats])\n",
        "\n",
        "# convert each label to a ont-hot vector, and then stack vectors as a matrix\n",
        "train_label_matrix = keras.utils.to_categorical(train_labels, num_classes=num_labels)\n",
        "valid_label_matrix = keras.utils.to_categorical(valid_labels, num_classes=num_labels)\n",
        "test_label_matrix = tf.keras.utils.to_categorical(test_labels, num_classes=num_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14b1fd1d",
      "metadata": {
        "id": "14b1fd1d"
      },
      "source": [
        "## Fine-Tune Model  \n",
        "    \n",
        "embedding_size  \n",
        "hidden_size  \n",
        "num_rnn_layers  \n",
        "num_mlp_layers  \n",
        "activation  \n",
        "dropout_rate  \n",
        "batch_norm  \n",
        "l2_reg  \n",
        "optimizer  \n",
        "learning_rate  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "63ef2920",
      "metadata": {
        "id": "63ef2920"
      },
      "outputs": [],
      "source": [
        "# set seed\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "71105160",
      "metadata": {
        "id": "71105160"
      },
      "outputs": [],
      "source": [
        "# indicator for saving models' weights\n",
        "count = 0\n",
        "\n",
        "# lstm\n",
        "rnn_type=\"lstm\"\n",
        "bidirectional=True\n",
        "\n",
        "# initial settings\n",
        "epoch = 30\n",
        "batch_size = 100\n",
        "\n",
        "embedding_size=100\n",
        "hidden_size=100\n",
        "num_rnn_layers=1\n",
        "num_mlp_layers=2\n",
        "activation='tanh'\n",
        "dropout_rate=0.5\n",
        "batch_norm=True\n",
        "l2_reg=0.005\n",
        "optimizer=\"Adam\"\n",
        "learning_rate=0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d734c154",
      "metadata": {
        "id": "d734c154"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "cd926c58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd926c58",
        "outputId": "7a1cb0d9-c1c8-4d54-c801-e2eb11291d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 1\n",
            "optimizer: SGD\n",
            "accuracy: 0.7531\n",
            "macro_f1: 0.7527\n",
            "----------------------------------------------------------------------------\n",
            "count: 2\n",
            "optimizer: RMSprop\n",
            "accuracy: 0.8025\n",
            "macro_f1: 0.8026\n",
            "----------------------------------------------------------------------------\n",
            "count: 3\n",
            "optimizer: Adam\n",
            "accuracy: 0.8049\n",
            "macro_f1: 0.8038\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "optimizer: Adam, accuracy: 0.8049382716049382, macro_f1: 0.8038014081868171\n"
          ]
        }
      ],
      "source": [
        "optimizer_list = ['SGD', 'RMSprop', 'Adam']\n",
        "best_optimizer = ''\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for optimizer in optimizer_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'optimizer: {optimizer}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_optimizer = optimizer\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'optimizer: {best_optimizer}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fae2666e",
      "metadata": {
        "id": "fae2666e"
      },
      "outputs": [],
      "source": [
        "optimizer = best_optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a67de14",
      "metadata": {
        "id": "1a67de14"
      },
      "source": [
        "### activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3026ae0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3026ae0b",
        "outputId": "858252e2-cfd5-4d70-e9a5-f50fa5b79097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 4\n",
            "activation: relu\n",
            "accuracy: 0.7951\n",
            "macro_f1: 0.7939\n",
            "----------------------------------------------------------------------------\n",
            "count: 5\n",
            "activation: tanh\n",
            "accuracy: 0.8099\n",
            "macro_f1: 0.8107\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "activation: tanh, accuracy: 0.8098765432098766, macro_f1: 0.8106764205691287\n"
          ]
        }
      ],
      "source": [
        "activation_list = ['relu', 'tanh']\n",
        "best_activation = ''\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for activation in activation_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'activation: {activation}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_activation = activation\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'activation: {best_activation}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "346af949",
      "metadata": {
        "id": "346af949"
      },
      "outputs": [],
      "source": [
        "activation = best_activation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dede6a89",
      "metadata": {
        "id": "dede6a89"
      },
      "source": [
        "### embedding_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9b74b026",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b74b026",
        "outputId": "56145b87-ea3b-41a3-be0b-c58ca1e8f7a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 6\n",
            "embedding_size: 50\n",
            "accuracy: 0.7827\n",
            "macro_f1: 0.7826\n",
            "----------------------------------------------------------------------------\n",
            "count: 7\n",
            "embedding_size: 75\n",
            "accuracy: 0.8198\n",
            "macro_f1: 0.8187\n",
            "----------------------------------------------------------------------------\n",
            "count: 8\n",
            "embedding_size: 100\n",
            "accuracy: 0.8198\n",
            "macro_f1: 0.8197\n",
            "----------------------------------------------------------------------------\n",
            "count: 9\n",
            "embedding_size: 128\n",
            "accuracy: 0.8099\n",
            "macro_f1: 0.8106\n",
            "----------------------------------------------------------------------------\n",
            "count: 10\n",
            "embedding_size: 256\n",
            "accuracy: 0.8222\n",
            "macro_f1: 0.8221\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "embedding_size: 256, accuracy: 0.8222222222222222, macro_f1: 0.8221498262910064\n"
          ]
        }
      ],
      "source": [
        "embedding_size_list = [50, 75, 100, 128, 256]\n",
        "best_embedding_size = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for embedding_size in embedding_size_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'embedding_size: {embedding_size}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_embedding_size = embedding_size\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'embedding_size: {best_embedding_size}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9bdfdc26",
      "metadata": {
        "id": "9bdfdc26"
      },
      "outputs": [],
      "source": [
        "embedding_size = best_embedding_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c091490",
      "metadata": {
        "id": "9c091490"
      },
      "source": [
        "### hidden_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e1a2e439",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a2e439",
        "outputId": "96908454-a2b7-418b-f36c-443bdb129977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 11\n",
            "hidden_size: 50\n",
            "accuracy: 0.8272\n",
            "macro_f1: 0.8281\n",
            "----------------------------------------------------------------------------\n",
            "count: 12\n",
            "hidden_size: 75\n",
            "accuracy: 0.8074\n",
            "macro_f1: 0.8069\n",
            "----------------------------------------------------------------------------\n",
            "count: 13\n",
            "hidden_size: 100\n",
            "accuracy: 0.8099\n",
            "macro_f1: 0.8116\n",
            "----------------------------------------------------------------------------\n",
            "count: 14\n",
            "hidden_size: 128\n",
            "accuracy: 0.8222\n",
            "macro_f1: 0.8218\n",
            "----------------------------------------------------------------------------\n",
            "count: 15\n",
            "hidden_size: 256\n",
            "accuracy: 0.8074\n",
            "macro_f1: 0.8071\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "hidden_size: 50, accuracy: 0.8271604938271605, macro_f1: 0.8280861722790646\n"
          ]
        }
      ],
      "source": [
        "hidden_size_list = [50, 75, 100, 128, 256]\n",
        "best_hidden_size = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for hidden_size in hidden_size_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'hidden_size: {hidden_size}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_hidden_size = hidden_size\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'hidden_size: {best_hidden_size}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b5d13981",
      "metadata": {
        "id": "b5d13981"
      },
      "outputs": [],
      "source": [
        "hidden_size = best_hidden_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78b04d57",
      "metadata": {
        "id": "78b04d57"
      },
      "source": [
        "### num_rnn_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8533e918",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8533e918",
        "outputId": "83b07bbf-5216-4765-d2b0-a7db71a6d489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 16\n",
            "num_rnn_layers: 1\n",
            "accuracy: 0.8123\n",
            "macro_f1: 0.8117\n",
            "----------------------------------------------------------------------------\n",
            "count: 17\n",
            "num_rnn_layers: 2\n",
            "accuracy: 0.8272\n",
            "macro_f1: 0.8269\n",
            "----------------------------------------------------------------------------\n",
            "count: 18\n",
            "num_rnn_layers: 3\n",
            "accuracy: 0.7852\n",
            "macro_f1: 0.7863\n",
            "----------------------------------------------------------------------------\n",
            "count: 19\n",
            "num_rnn_layers: 4\n",
            "accuracy: 0.7975\n",
            "macro_f1: 0.7974\n",
            "----------------------------------------------------------------------------\n",
            "count: 20\n",
            "num_rnn_layers: 5\n",
            "accuracy: 0.8049\n",
            "macro_f1: 0.8047\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "num_rnn_layers: 2, accuracy: 0.8271604938271605, macro_f1: 0.8268787504917318\n"
          ]
        }
      ],
      "source": [
        "num_rnn_layers_list = [1, 2, 3, 4, 5]\n",
        "best_num_rnn_layers = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for num_rnn_layers in num_rnn_layers_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'num_rnn_layers: {num_rnn_layers}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_num_rnn_layers = num_rnn_layers\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'num_rnn_layers: {best_num_rnn_layers}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0dd3e868",
      "metadata": {
        "id": "0dd3e868"
      },
      "outputs": [],
      "source": [
        "num_rnn_layers = best_num_rnn_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1592cf65",
      "metadata": {
        "id": "1592cf65"
      },
      "source": [
        "### num_mlp_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7506f58a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7506f58a",
        "outputId": "ed08304a-b946-47ab-ee6b-a49448c6d456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 21\n",
            "num_mlp_layers: 1\n",
            "accuracy: 0.7778\n",
            "macro_f1: 0.7789\n",
            "----------------------------------------------------------------------------\n",
            "count: 22\n",
            "num_mlp_layers: 2\n",
            "accuracy: 0.8123\n",
            "macro_f1: 0.8120\n",
            "----------------------------------------------------------------------------\n",
            "count: 23\n",
            "num_mlp_layers: 3\n",
            "accuracy: 0.8198\n",
            "macro_f1: 0.8202\n",
            "----------------------------------------------------------------------------\n",
            "count: 24\n",
            "num_mlp_layers: 4\n",
            "accuracy: 0.8123\n",
            "macro_f1: 0.8116\n",
            "----------------------------------------------------------------------------\n",
            "count: 25\n",
            "num_mlp_layers: 5\n",
            "accuracy: 0.8074\n",
            "macro_f1: 0.8086\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "num_mlp_layers: 3, accuracy: 0.8197530864197531, macro_f1: 0.8201965931106879\n"
          ]
        }
      ],
      "source": [
        "num_mlp_layers_list = [1, 2, 3, 4, 5]\n",
        "best_num_mlp_layers = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for num_mlp_layers in num_mlp_layers_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'num_mlp_layers: {num_mlp_layers}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_num_mlp_layers = num_mlp_layers\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'num_mlp_layers: {best_num_mlp_layers}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "dc770393",
      "metadata": {
        "id": "dc770393"
      },
      "outputs": [],
      "source": [
        "num_mlp_layers = best_num_mlp_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b303efe",
      "metadata": {
        "id": "7b303efe"
      },
      "source": [
        "### dropout_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "e14a1e2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e14a1e2b",
        "outputId": "f5a2de22-943b-4edc-b667-480e7b6aa5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 26\n",
            "dropout_rate: 0.1\n",
            "accuracy: 0.8074\n",
            "macro_f1: 0.8053\n",
            "----------------------------------------------------------------------------\n",
            "count: 27\n",
            "dropout_rate: 0.3\n",
            "accuracy: 0.8049\n",
            "macro_f1: 0.8048\n",
            "----------------------------------------------------------------------------\n",
            "count: 28\n",
            "dropout_rate: 0.5\n",
            "accuracy: 0.8173\n",
            "macro_f1: 0.8165\n",
            "----------------------------------------------------------------------------\n",
            "count: 29\n",
            "dropout_rate: 0.6\n",
            "accuracy: 0.7951\n",
            "macro_f1: 0.7997\n",
            "----------------------------------------------------------------------------\n",
            "count: 30\n",
            "dropout_rate: 0.7\n",
            "accuracy: 0.7926\n",
            "macro_f1: 0.7916\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "dropout_rate: 0.5, accuracy: 0.817283950617284, macro_f1: 0.8164891443673582\n"
          ]
        }
      ],
      "source": [
        "dropout_rate_list = [0.1, 0.3, 0.5, 0.6, 0.7]\n",
        "best_dropout_rate = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for dropout_rate in dropout_rate_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'dropout_rate: {dropout_rate}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_dropout_rate = dropout_rate\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'dropout_rate: {best_dropout_rate}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ba777e48",
      "metadata": {
        "id": "ba777e48"
      },
      "outputs": [],
      "source": [
        "dropout_rate = best_dropout_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f464f5e",
      "metadata": {
        "id": "5f464f5e"
      },
      "source": [
        "### batch_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "98773c3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98773c3c",
        "outputId": "af6f1207-eee2-46ac-8734-d35fdebeede4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 31\n",
            "batch_norm: True\n",
            "accuracy: 0.8074\n",
            "macro_f1: 0.8070\n",
            "----------------------------------------------------------------------------\n",
            "count: 32\n",
            "batch_norm: False\n",
            "accuracy: 0.7926\n",
            "macro_f1: 0.7898\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "batch_norm: True, accuracy: 0.8074074074074075, macro_f1: 0.8069876443462721\n"
          ]
        }
      ],
      "source": [
        "batch_norm_list = [True, False]\n",
        "best_batch_norm = False\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for batch_norm in batch_norm_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'batch_norm: {batch_norm}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_batch_norm = batch_norm\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'batch_norm: {best_batch_norm}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "6df6104a",
      "metadata": {
        "id": "6df6104a"
      },
      "outputs": [],
      "source": [
        "batch_norm = best_batch_norm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58c91175",
      "metadata": {
        "id": "58c91175"
      },
      "source": [
        "### l2_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "54f3758c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54f3758c",
        "outputId": "d4325c88-8bb7-4bc3-d54b-9477b744f63d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 33\n",
            "l2_reg: 0.001\n",
            "accuracy: 0.8272\n",
            "macro_f1: 0.8271\n",
            "----------------------------------------------------------------------------\n",
            "count: 34\n",
            "l2_reg: 0.005\n",
            "accuracy: 0.8420\n",
            "macro_f1: 0.8419\n",
            "----------------------------------------------------------------------------\n",
            "count: 35\n",
            "l2_reg: 0.01\n",
            "accuracy: 0.8000\n",
            "macro_f1: 0.7984\n",
            "----------------------------------------------------------------------------\n",
            "count: 36\n",
            "l2_reg: 0.1\n",
            "accuracy: 0.8173\n",
            "macro_f1: 0.8161\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "l2_reg: 0.005, accuracy: 0.8419753086419753, macro_f1: 0.8418516518737417\n"
          ]
        }
      ],
      "source": [
        "l2_reg_list = [0.001, 0.005, 0.01, 0.1]\n",
        "best_l2_reg = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for l2_reg in l2_reg_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'l2_reg: {l2_reg}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_l2_reg = l2_reg\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'l2_reg: {best_l2_reg}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5333252d",
      "metadata": {
        "id": "5333252d"
      },
      "outputs": [],
      "source": [
        "l2_reg = best_l2_reg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6904d64d",
      "metadata": {
        "id": "6904d64d"
      },
      "source": [
        "### learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9a8893a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a8893a0",
        "outputId": "3c64e5ac-725e-4c01-e4e5-6298a97ee71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 37\n",
            "learning_rate: 0.0001\n",
            "accuracy: 0.8123\n",
            "macro_f1: 0.8118\n",
            "----------------------------------------------------------------------------\n",
            "count: 38\n",
            "learning_rate: 0.001\n",
            "accuracy: 0.8198\n",
            "macro_f1: 0.8192\n",
            "----------------------------------------------------------------------------\n",
            "count: 39\n",
            "learning_rate: 0.01\n",
            "accuracy: 0.8025\n",
            "macro_f1: 0.8009\n",
            "----------------------------------------------------------------------------\n",
            "count: 40\n",
            "learning_rate: 0.1\n",
            "accuracy: 0.8222\n",
            "macro_f1: 0.8229\n",
            "----------------------------------------------------------------------------\n",
            "Best model:\n",
            "learning_rate: 0.1, accuracy: 0.8222222222222222, macro_f1: 0.8228964264789124\n"
          ]
        }
      ],
      "source": [
        "learning_rate_list = [0.0001, 0.001, 0.01, 0.1]\n",
        "best_learning_rate = 0\n",
        "best_acc = 0\n",
        "best_f1 = 0\n",
        "\n",
        "for learning_rate in learning_rate_list:\n",
        "\n",
        "    count += 1\n",
        "\n",
        "    model = build_RNN(input_length=max_len, \n",
        "                          vocab_size=len(feats_dict), \n",
        "                          embedding_size=embedding_size,\n",
        "                          hidden_size=hidden_size, \n",
        "                          output_size=9,\n",
        "                          num_rnn_layers=num_rnn_layers, \n",
        "                          num_mlp_layers=num_mlp_layers,\n",
        "                          rnn_type=rnn_type,\n",
        "                          bidirectional=bidirectional,\n",
        "                          activation=activation,\n",
        "                          dropout_rate=dropout_rate,\n",
        "                          batch_norm=batch_norm,\n",
        "                          l2_reg=l2_reg,\n",
        "                          optimizer=optimizer,\n",
        "                          learning_rate=learning_rate,\n",
        "                        )\n",
        "\n",
        "    checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"),\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=0,\n",
        "        save_best_only=True)\n",
        "\n",
        "    mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                        validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                        epochs=epoch, batch_size=batch_size, verbose=0,\n",
        "                        callbacks=[checkpointer])\n",
        "\n",
        "    model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_tune{count}.hdf5\"))\n",
        "\n",
        "    print(f'count: {count}')\n",
        "    print(f'learning_rate: {learning_rate}')\n",
        "\n",
        "    # evaluation\n",
        "    # generate prediction and format\n",
        "    y_pred = model.predict(valid_feats_matrix)\n",
        "    y_pred = [np.argmax(row) for row in y_pred]\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    # evaluate performance\n",
        "    acc = accuracy_score(valid_labels, y_pred)\n",
        "    f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "    print(f'accuracy: {acc:.4f}')\n",
        "    print(f'macro_f1: {f1:.4f}')\n",
        "\n",
        "    # save best model\n",
        "    if f1 > best_f1:\n",
        "        best_learning_rate = learning_rate\n",
        "        best_acc = acc\n",
        "        best_f1 = f1\n",
        "    \n",
        "    print('----------------------------------------------------------------------------')\n",
        "\n",
        "print('Best model:')\n",
        "print(f'learning_rate: {best_learning_rate}, accuracy: {best_acc}, macro_f1: {best_f1}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c17054f7",
      "metadata": {
        "id": "c17054f7"
      },
      "outputs": [],
      "source": [
        "learning_rate = best_learning_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31a48114",
      "metadata": {
        "id": "31a48114"
      },
      "source": [
        "## Final Bi-Directional LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "41a2d96e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41a2d96e",
        "outputId": "9b6edc88-a8e7-4a96-a5ca-8caff48a652a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "37/37 [==============================] - 9s 69ms/step - loss: 3.2399 - accuracy: 0.1630 - precision_47: 0.2000 - recall_47: 0.0033 - val_loss: 2.9137 - val_accuracy: 0.3901 - val_precision_47: 0.0000e+00 - val_recall_47: 0.0000e+00\n",
            "Epoch 2/30\n",
            "37/37 [==============================] - 1s 26ms/step - loss: 2.2163 - accuracy: 0.5520 - precision_47: 0.8249 - recall_47: 0.2598 - val_loss: 2.2209 - val_accuracy: 0.6494 - val_precision_47: 0.9800 - val_recall_47: 0.1210\n",
            "Epoch 3/30\n",
            "37/37 [==============================] - 1s 26ms/step - loss: 1.4471 - accuracy: 0.8239 - precision_47: 0.9046 - recall_47: 0.7075 - val_loss: 1.6911 - val_accuracy: 0.8099 - val_precision_47: 0.9417 - val_recall_47: 0.4790\n",
            "Epoch 4/30\n",
            "37/37 [==============================] - 1s 26ms/step - loss: 1.0942 - accuracy: 0.9064 - precision_47: 0.9420 - recall_47: 0.8516 - val_loss: 1.4463 - val_accuracy: 0.8148 - val_precision_47: 0.9314 - val_recall_47: 0.6370\n",
            "Epoch 5/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.8820 - accuracy: 0.9454 - precision_47: 0.9632 - recall_47: 0.9188 - val_loss: 1.3404 - val_accuracy: 0.7877 - val_precision_47: 0.8899 - val_recall_47: 0.6988\n",
            "Epoch 6/30\n",
            "37/37 [==============================] - 1s 25ms/step - loss: 0.7254 - accuracy: 0.9690 - precision_47: 0.9800 - recall_47: 0.9550 - val_loss: 1.2269 - val_accuracy: 0.8173 - val_precision_47: 0.8812 - val_recall_47: 0.7506\n",
            "Epoch 7/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.6167 - accuracy: 0.9794 - precision_47: 0.9828 - recall_47: 0.9706 - val_loss: 1.1934 - val_accuracy: 0.8000 - val_precision_47: 0.8493 - val_recall_47: 0.7654\n",
            "Epoch 8/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.5235 - accuracy: 0.9846 - precision_47: 0.9897 - recall_47: 0.9794 - val_loss: 1.1303 - val_accuracy: 0.7852 - val_precision_47: 0.8333 - val_recall_47: 0.7654\n",
            "Epoch 9/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.4530 - accuracy: 0.9874 - precision_47: 0.9909 - recall_47: 0.9824 - val_loss: 1.1753 - val_accuracy: 0.7877 - val_precision_47: 0.8347 - val_recall_47: 0.7605\n",
            "Epoch 10/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3771 - accuracy: 0.9909 - precision_47: 0.9942 - recall_47: 0.9898 - val_loss: 1.1531 - val_accuracy: 0.8025 - val_precision_47: 0.8211 - val_recall_47: 0.7704\n",
            "Epoch 11/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.3230 - accuracy: 0.9937 - precision_47: 0.9953 - recall_47: 0.9909 - val_loss: 1.2161 - val_accuracy: 0.7778 - val_precision_47: 0.8031 - val_recall_47: 0.7556\n",
            "Epoch 12/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2722 - accuracy: 0.9962 - precision_47: 0.9970 - recall_47: 0.9951 - val_loss: 1.1889 - val_accuracy: 0.7753 - val_precision_47: 0.8010 - val_recall_47: 0.7556\n",
            "Epoch 13/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.2365 - accuracy: 0.9951 - precision_47: 0.9959 - recall_47: 0.9940 - val_loss: 1.1278 - val_accuracy: 0.7704 - val_precision_47: 0.8079 - val_recall_47: 0.7580\n",
            "Epoch 14/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.1929 - accuracy: 0.9962 - precision_47: 0.9964 - recall_47: 0.9959 - val_loss: 1.1251 - val_accuracy: 0.7926 - val_precision_47: 0.8175 - val_recall_47: 0.7852\n",
            "Epoch 15/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.1720 - accuracy: 0.9967 - precision_47: 0.9967 - recall_47: 0.9964 - val_loss: 1.1872 - val_accuracy: 0.7531 - val_precision_47: 0.8005 - val_recall_47: 0.7432\n",
            "Epoch 16/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.1476 - accuracy: 0.9948 - precision_47: 0.9970 - recall_47: 0.9940 - val_loss: 1.1092 - val_accuracy: 0.7778 - val_precision_47: 0.8031 - val_recall_47: 0.7654\n",
            "Epoch 17/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.1279 - accuracy: 0.9953 - precision_47: 0.9964 - recall_47: 0.9945 - val_loss: 1.1608 - val_accuracy: 0.7481 - val_precision_47: 0.7818 - val_recall_47: 0.7432\n",
            "Epoch 18/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.1451 - accuracy: 0.9841 - precision_47: 0.9854 - recall_47: 0.9800 - val_loss: 1.1496 - val_accuracy: 0.7877 - val_precision_47: 0.8067 - val_recall_47: 0.7728\n",
            "Epoch 19/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.1262 - accuracy: 0.9874 - precision_47: 0.9890 - recall_47: 0.9871 - val_loss: 1.1470 - val_accuracy: 0.7704 - val_precision_47: 0.7903 - val_recall_47: 0.7630\n",
            "Epoch 20/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.1053 - accuracy: 0.9907 - precision_47: 0.9926 - recall_47: 0.9879 - val_loss: 1.1163 - val_accuracy: 0.7951 - val_precision_47: 0.8222 - val_recall_47: 0.7877\n",
            "Epoch 21/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0952 - accuracy: 0.9904 - precision_47: 0.9915 - recall_47: 0.9890 - val_loss: 1.2084 - val_accuracy: 0.7852 - val_precision_47: 0.7895 - val_recall_47: 0.7778\n",
            "Epoch 22/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.0848 - accuracy: 0.9920 - precision_47: 0.9929 - recall_47: 0.9912 - val_loss: 1.1559 - val_accuracy: 0.8000 - val_precision_47: 0.8122 - val_recall_47: 0.7901\n",
            "Epoch 23/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.0750 - accuracy: 0.9904 - precision_47: 0.9909 - recall_47: 0.9890 - val_loss: 1.1340 - val_accuracy: 0.8025 - val_precision_47: 0.8131 - val_recall_47: 0.7951\n",
            "Epoch 24/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0650 - accuracy: 0.9926 - precision_47: 0.9939 - recall_47: 0.9915 - val_loss: 1.1165 - val_accuracy: 0.7901 - val_precision_47: 0.8051 - val_recall_47: 0.7852\n",
            "Epoch 25/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.0467 - accuracy: 0.9973 - precision_47: 0.9984 - recall_47: 0.9970 - val_loss: 1.2175 - val_accuracy: 0.7975 - val_precision_47: 0.8147 - val_recall_47: 0.7926\n",
            "Epoch 26/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0493 - accuracy: 0.9948 - precision_47: 0.9948 - recall_47: 0.9945 - val_loss: 1.2698 - val_accuracy: 0.7926 - val_precision_47: 0.8065 - val_recall_47: 0.7926\n",
            "Epoch 27/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0565 - accuracy: 0.9934 - precision_47: 0.9940 - recall_47: 0.9934 - val_loss: 1.2143 - val_accuracy: 0.7951 - val_precision_47: 0.8025 - val_recall_47: 0.7926\n",
            "Epoch 28/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0434 - accuracy: 0.9945 - precision_47: 0.9945 - recall_47: 0.9940 - val_loss: 1.2665 - val_accuracy: 0.8025 - val_precision_47: 0.8127 - val_recall_47: 0.7926\n",
            "Epoch 29/30\n",
            "37/37 [==============================] - 1s 24ms/step - loss: 0.0433 - accuracy: 0.9942 - precision_47: 0.9942 - recall_47: 0.9934 - val_loss: 1.3676 - val_accuracy: 0.7753 - val_precision_47: 0.7908 - val_recall_47: 0.7654\n",
            "Epoch 30/30\n",
            "37/37 [==============================] - 1s 23ms/step - loss: 0.0480 - accuracy: 0.9915 - precision_47: 0.9926 - recall_47: 0.9909 - val_loss: 1.3340 - val_accuracy: 0.7951 - val_precision_47: 0.8060 - val_recall_47: 0.7901\n",
            "count: 40\n",
            "learning_rate: 0.1\n",
            "accuracy: 0.8173\n",
            "macro_f1: 0.8155\n"
          ]
        }
      ],
      "source": [
        "model = build_RNN(input_length=max_len, \n",
        "                      vocab_size=len(feats_dict), \n",
        "                      embedding_size=embedding_size,\n",
        "                      hidden_size=hidden_size, \n",
        "                      output_size=9,\n",
        "                      num_rnn_layers=num_rnn_layers, \n",
        "                      num_mlp_layers=num_mlp_layers,\n",
        "                      rnn_type=rnn_type,\n",
        "                      bidirectional=bidirectional,\n",
        "                      activation=activation,\n",
        "                      dropout_rate=dropout_rate,\n",
        "                      batch_norm=batch_norm,\n",
        "                      l2_reg=l2_reg,\n",
        "                      optimizer=optimizer,\n",
        "                      learning_rate=learning_rate,\n",
        "                    )\n",
        "\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=os.path.join(\"models\", f\"weights_RNN_final.hdf5\"),\n",
        "    monitor=\"val_accuracy\",\n",
        "    verbose=0,\n",
        "    save_best_only=True)\n",
        "\n",
        "mlp_history = model.fit(train_feats_matrix, train_label_matrix,\n",
        "                    validation_data=(valid_feats_matrix, valid_label_matrix),\n",
        "                    epochs=epoch, batch_size=batch_size, verbose=1,\n",
        "                    callbacks=[checkpointer])\n",
        "\n",
        "model = keras.models.load_model(os.path.join(\"models\", f\"weights_RNN_final.hdf5\"))\n",
        "\n",
        "print(f'count: {count}')\n",
        "print(f'learning_rate: {learning_rate}')\n",
        "\n",
        "# evaluation\n",
        "# generate prediction and format\n",
        "y_pred = model.predict(valid_feats_matrix)\n",
        "y_pred = [np.argmax(row) for row in y_pred]\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# evaluate performance\n",
        "acc = accuracy_score(valid_labels, y_pred)\n",
        "f1 = f1_score(valid_labels, y_pred, average='macro')\n",
        "print(f'accuracy: {acc:.4f}')\n",
        "print(f'macro_f1: {f1:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be611d51",
      "metadata": {
        "id": "be611d51"
      },
      "source": [
        "## Final Model Test Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "c481ea3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c481ea3e",
        "outputId": "683fa5a3-569b-42f7-f9f7-137e59308114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 0.8311\n",
            "test macro_f1: 0.8292\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.90      0.88      0.89        50\n",
            "          NC       0.85      0.92      0.88        50\n",
            "          PW       0.80      0.86      0.83        50\n",
            "          HC       0.79      0.62      0.70        50\n",
            "          PL       0.83      0.78      0.80        50\n",
            "          CR       0.82      0.82      0.82        50\n",
            "          CG       0.85      0.82      0.84        50\n",
            "          BE       0.77      0.88      0.82        50\n",
            "           N       0.87      0.90      0.88        50\n",
            "\n",
            "    accuracy                           0.83       450\n",
            "   macro avg       0.83      0.83      0.83       450\n",
            "weighted avg       0.83      0.83      0.83       450\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# generate prediction and format\n",
        "y_pred = model.predict(test_feats_matrix)\n",
        "y_pred = [np.argmax(row) for row in y_pred]\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "# evaluate performance\n",
        "acc = accuracy_score(test_labels, y_pred)\n",
        "f1 = f1_score(test_labels, y_pred, average='macro')\n",
        "print(f'test accuracy: {acc:.4f}')\n",
        "print(f'test macro_f1: {f1:.4f}')\n",
        "print(classification_report(test_labels, y_pred,target_names=labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix\n",
        "cm = confusion_matrix(test_labels, y_pred , normalize='pred')\n",
        "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "cmp.plot(ax=ax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "lc5vlinRMTft",
        "outputId": "42c91a27-bc8e-4b74-9b18-96a0f10ba599"
      },
      "id": "lc5vlinRMTft",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f880095fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "80Agz3ECMU6y"
      },
      "id": "80Agz3ECMU6y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "name": "UROP_bi_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}