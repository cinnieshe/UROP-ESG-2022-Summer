{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNt9GHQ6EWKO",
    "outputId": "997cef41-9c8b-45f2-c0d0-5c5fbb04cb00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.7 MB 5.2 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101 kB 13.1 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 68.4 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.6 MB 43.2 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365 kB 8.3 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141 kB 55.3 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 115 kB 65.1 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212 kB 17.9 MB/s \n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127 kB 7.1 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install transformers --quiet\n",
    "!pip install datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:30:37.970878Z",
     "start_time": "2022-06-02T02:30:34.740917Z"
    },
    "id": "qzLjYunsEH67"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from transformers import BertTokenizer, Trainer, BertForSequenceClassification, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:45:07.491364Z",
     "start_time": "2022-06-02T02:45:07.482746Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feXeWBEbEH69",
    "outputId": "8ae564ee-a1af-47d6-ed83-3b4e0b0fc1d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.12.0+cu113', '4.21.1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tested in transformers==4.18.0, pytorch==1.7.1 \n",
    "import torch\n",
    "import transformers\n",
    "torch.__version__, transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:44:25.431428Z",
     "start_time": "2022-06-02T02:44:25.423127Z"
    },
    "id": "XMRatd3MEH6_"
   },
   "source": [
    "*Note: the following code is for demonstration purpose. Please use GPU for fast inference on large scale dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:44:18.286115Z",
     "start_time": "2022-06-02T02:44:18.222850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ThtE8KarEH7A",
    "outputId": "149508ab-b2b5-489b-83e9-461cda9ce2ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM5XgG2iEH7B"
   },
   "source": [
    "### load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c98-dI6AEjqx",
    "outputId": "41168f75-bacf-4cf5-878c-5db86924db65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:06.431016Z",
     "start_time": "2022-06-02T02:54:06.391735Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bld9ujGZEH7C",
    "outputId": "d8dbc0e6-9eed-46cc-dd5f-81f25ca41073"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-d15e20f9-29d7-422f-95fc-9e22ee41c913\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apache also has recycled more than 1.2 million...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We have the largest full-time union workforce ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comprehensive Risk We strengthened our busines...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In 2011, Walmart China began a collaboration w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wherever Agilent is in the world, we adhere to...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d15e20f9-29d7-422f-95fc-9e22ee41c913')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-d15e20f9-29d7-422f-95fc-9e22ee41c913 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-d15e20f9-29d7-422f-95fc-9e22ee41c913');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  Apache also has recycled more than 1.2 million...      1\n",
       "1  We have the largest full-time union workforce ...      3\n",
       "2  Comprehensive Risk We strengthened our busines...      7\n",
       "3  In 2011, Walmart China began a collaboration w...      2\n",
       "4  Wherever Agilent is in the world, we adhere to...      7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/MyDrive/final_dataset_formatted.csv') ## use your own customized dataset\n",
    "df_test = pd.read_csv('/content/drive/MyDrive/final_dataset_formatted_test.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:06.895445Z",
     "start_time": "2022-06-02T02:54:06.880863Z"
    },
    "id": "PusiqSfLEH7C"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['sentence', 'label']) ## drop missing values\n",
    "df_test = df_test.dropna(subset=['sentence', 'label']) ## drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmVl8L1bHX2d",
    "outputId": "549cb0bc-7c9f-48fa-c5e9-96d3474ae1d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4050, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY31kalTEH7D"
   },
   "source": [
    "### prepare training/validation/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:08.030875Z",
     "start_time": "2022-06-02T02:54:07.999354Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUuxNysNEH7E",
    "outputId": "ea13113f-39a6-439a-cbe8-59fbf93da248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3645, 2) (450, 2) (405, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val = train_test_split(df, stratify=df['label'],test_size=0.1, random_state=42)\n",
    "print(df_train.shape, df_test.shape, df_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fodlT46EH7F"
   },
   "source": [
    "### load FinBERT pretrained model\n",
    "The pretrained FinBERT model path on Huggingface is https://huggingface.co/yiyanghkust/finbert-pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BOZXEcxij5Qp"
   },
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:17.945203Z",
     "start_time": "2022-06-02T02:54:10.422200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "a2a793b2c70342bb8197b0118257bc25",
      "f7f7bfc413164704801f0371f4c484a6",
      "a9db3bd1c5e3463a98718ee9ec747906",
      "195aa78cdb97457283b581d2593b74ff",
      "44302aa2ce354b12b36a78e1754d4921",
      "11e3a67c3c99464c865b4a251d1cb8b8",
      "c77926deb85142509fc8dd5f4557f481",
      "e0a9888ac2da45d395e79c18ff52ba6a",
      "7aea2ca670b346e19dc7e78a9b7959a1",
      "cf4c061b877442ef833e35c6394417cb",
      "9dd4b3bc280a4ea0aa52545659fa59c8",
      "9d81803847ea4539a746100dd1da99b3",
      "52322215b3f44c5d8474b541d736f1ca",
      "58faba1e48274d138778a1087ebafe06",
      "4bf0f86104944eb091686b09bd9f3703",
      "d945141252824e2c9503ff72414d0d4a",
      "3a56f4ad0b8e4503a5e9062b621d0734",
      "385d8170daa54770976277e2203ecdc8",
      "e1bd8fd10ff54964883518aff23f2509",
      "435acf4cc6c9403b884282e8ffe8a719",
      "4702b9ef04b64b76b119ead21ffe3c01",
      "d5826321f95e4e8ab5be15c466fa305c",
      "5316e1b0beb74b4bb883ee7d0248cae5",
      "79feb316f4624f42abe2ee960432f70b",
      "9023a6bc41a54024b100c929e431c574",
      "9470fa1726f74865850bff4e4588785d",
      "7beffc1cc87b4308beaecc7cd59e0a98",
      "d64fd3c9e131424e89ccca026e262bef",
      "edb6570cd8ed4e1b89a9a5f96b3152cf",
      "5e771f6e6b9b4eceac24da3921bc2236",
      "04b360c8ca1c40e1a67e731a7da357e4",
      "1a8c273f4019462b90c58707d85aaf1f",
      "cecf22af54f04ba895921837c93ab13a",
      "cd3ab6890ec145a0abe3af2330886291",
      "d9ca713f5666406181e97d8b36a7c142",
      "56edee92c70441b9af9f508499092211",
      "5ae2706f9e9846f49315355f922ef150",
      "dca9fd04fe5e400d972d11be330a25f0",
      "901f1c3d78ec41ff8eceed365dd19617",
      "31b58fdf2a454a42a1daf7bb4af135e3",
      "ee55d874ecfe46449d3b50403395f48d",
      "74f5030c80a54244b59431a402f2eb60",
      "4b540654eb65490ba6248f09025482d7",
      "f6c1cbacce68433bb90fcaecb518139b"
     ]
    },
    "id": "oWu2LHUhEH7F",
    "outputId": "3cdb5e01-cd62-4bdf-a2a8-eab96df5cb58"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a793b2c70342bb8197b0118257bc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d81803847ea4539a746100dd1da99b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5316e1b0beb74b4bb883ee7d0248cae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3ab6890ec145a0abe3af2330886291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name,num_labels=9)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:37:33.687054Z",
     "start_time": "2022-06-02T02:37:33.664650Z"
    },
    "id": "w22rTOuUEH7G"
   },
   "source": [
    "### prepare dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:54:33.660010Z",
     "start_time": "2022-06-02T02:54:17.948143Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "063cb2cc34204b11bf8577b9dd6feb1e",
      "074333194c95425bb3c4819c1efc0c07",
      "3c66e813c83a4ae19e4fde1c6281cf98",
      "16563c0a5d56425f8a8601954699d0b9",
      "d8dde5f76b48491f889823a5d158c784",
      "2d2d814a03e64972aae6d439a9dc6f57",
      "42768db2dbe1450ebe28bdf42ea035ea",
      "d75cbe4f57744c61a97d932895c03674",
      "3084b2c0f4224d02a9930010fe8bb464",
      "35c4d256528f4fa29f1164860a3cb240",
      "2a42c673b846416daa467e2ad1295fee",
      "45a1ff6c483c4778975d23b1678a20ec",
      "9d9d40854b84490789553234e5a35a40",
      "3361842b7d6d4bc99d7f433dcdb92fad",
      "e526a5a0774d4f11ba4a930c96f4acde",
      "9acf6884b3d84c35bab7426ccb8b23a2",
      "a20a1f2a8e124ee2839c8446da973de7",
      "9ab9ed080bfb45adb2fa2a273d0df72e",
      "5528b219a3e2452abe0a7b51514717fd",
      "05b0e5057bc5420590c193bc1a2c1527",
      "51cacaebc8b945ad985e04a191abf8cc",
      "06df290212cd4dce9dee6850731cb43e",
      "fe9db4c873d946c6a9a75698c8114836",
      "545acd2b59ca4d85a33f45caa1b131e2",
      "9d59614f0b854d9794763381bfb8d7a5",
      "7d03510396b743a7bb47481f0d52000e",
      "9c8461ed6ed94d2eb09052d0fea5fed9",
      "cf04d1efdce24e459fc3342bdfbbdf05",
      "a3943813f7f3402e8edcaa673550ab0a",
      "13ff27616bec449ab422ec112fba008c",
      "9d9b6126b6b84063bf126056e306fa88",
      "717b37ed7e844b28b4fbf8c84b1d5b0c",
      "d16104a6ae0445fea2301e0d93083dac"
     ]
    },
    "id": "BxmvuLu-EH7G",
    "outputId": "f0dc7b5f-65dd-4d06-febb-906eac8b8bd6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063cb2cc34204b11bf8577b9dd6feb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a1ff6c483c4778975d23b1678a20ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9db4c873d946c6a9a75698c8114836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['CC', 'NC', 'PW', 'HC', 'PL', 'CR', 'CG', 'BE', 'N']\n",
    "\n",
    "dataset_train = Dataset.from_pandas(df_train)\n",
    "dataset_val = Dataset.from_pandas(df_val)\n",
    "dataset_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "dataset_train = dataset_train.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "dataset_val = dataset_val.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
    "dataset_test = dataset_test.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length' , max_length=128), batched=True)\n",
    "\n",
    "dataset_train.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "dataset_val.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n",
    "dataset_test.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7gjFwjEEH7G"
   },
   "source": [
    "### **First Trial:** \n",
    "### define training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kGjmYDFGw7rG"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'accuracy' : accuracy_score(predictions, labels), 'macro-f1' : f1_score(predictions, labels, average='macro')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T02:57:15.963784Z",
     "start_time": "2022-06-02T02:54:33.662575Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q1a8JrgYEH7H",
    "outputId": "90ecb617-eee3-494e-98c5-dc410cc94cf4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.859890</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.810614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.500443</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.441712</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.455498</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.868627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.457251</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.863692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-456 (score: 0.8691358024691358).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=570, training_loss=0.5322596365945381, metrics={'train_runtime': 443.8924, 'train_samples_per_second': 41.057, 'train_steps_per_second': 1.284, 'total_flos': 1198875090758400.0, 'train_loss': 0.5322596365945381, 'epoch': 5.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "        output_dir = 'temp/',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        num_train_epochs=5,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        args=args,                  # training arguments, defined above\n",
    "        train_dataset=dataset_train,         # training dataset\n",
    "        eval_dataset=dataset_val,            # evaluation dataset\n",
    "        compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv0eZ5NSEH7H"
   },
   "source": [
    "### evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "9iebJjbYUOgr",
    "outputId": "df3edaef-c7fc-4804-b882-8ef843d05415"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4554983377456665, 'test_accuracy': 0.8691358024691358, 'test_macro-f1': 0.8686266056704888, 'test_runtime': 3.2468, 'test_samples_per_second': 124.738, 'test_steps_per_second': 4.004} \n",
      "\n",
      "accuracy 0.8691358024691358\n",
      "macro_f1 score: 0.8686266056704888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.91      0.91      0.91        45\n",
      "          NC       0.92      0.98      0.95        45\n",
      "          PW       0.93      0.93      0.93        45\n",
      "          HC       0.85      0.76      0.80        45\n",
      "          PL       0.75      0.80      0.77        45\n",
      "          CR       0.90      0.80      0.85        45\n",
      "          CG       0.82      0.93      0.87        45\n",
      "          BE       0.85      0.87      0.86        45\n",
      "           N       0.90      0.84      0.87        45\n",
      "\n",
      "    accuracy                           0.87       405\n",
      "   macro avg       0.87      0.87      0.87       405\n",
      "weighted avg       0.87      0.87      0.87       405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate prediction\n",
    "predictions = trainer.predict(dataset_val)\n",
    "print(predictions.metrics, '\\n')\n",
    "y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "# evaluate model performance\n",
    "f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "print('accuracy %s' % accuracy_score(y_pred, predictions[1]))\n",
    "print(f'macro_f1 score: {f1}')\n",
    "print(classification_report(predictions[1], y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tJjzhWiEH7I"
   },
   "source": [
    "### save the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T03:09:11.599174Z",
     "start_time": "2022-06-02T03:09:10.847115Z"
    },
    "id": "eP_i-umoEH7I"
   },
   "outputs": [],
   "source": [
    "# trainer.save_model('finbert-sentiment/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PixbmS6TInTc"
   },
   "source": [
    "## **Fine-Tuning FinBERT Model**  \n",
    "  \n",
    "learning_rate   \n",
    "weight_decay   \n",
    "num_train_epochs  \n",
    "per_device_train_batch_size  \n",
    "per_device_eval_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZOEo6bhGSk_L"
   },
   "outputs": [],
   "source": [
    "# initial hyperparameters settings\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0\n",
    "num_train_epochs = 5.0\n",
    "per_device_train_batch_size = 32\n",
    "per_device_eval_batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s72LWCKTPGW"
   },
   "source": [
    "### learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KJyKml6gIqr9",
    "outputId": "e6e51627-17b8-49ce-f179-a3f0b4f84adb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.851200</td>\n",
       "      <td>1.422957</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.723343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.071000</td>\n",
       "      <td>0.798492</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>0.834339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.591385</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.844155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.526444</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.856479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.506615</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-570 (score: 0.8592592592592593).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 1e-05\n",
      " {'test_loss': 0.5066152215003967, 'test_accuracy': 0.8592592592592593, 'test_macro-f1': 0.859124237735564, 'test_runtime': 3.2479, 'test_samples_per_second': 124.695, 'test_steps_per_second': 4.003} \n",
      "\n",
      "accuracy 0.8592592592592593\n",
      "macro_f1 score: 0.859124237735564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.87      0.87      0.87        45\n",
      "          NC       0.91      0.93      0.92        45\n",
      "          PW       0.89      0.91      0.90        45\n",
      "          HC       0.82      0.82      0.82        45\n",
      "          PL       0.80      0.78      0.79        45\n",
      "          CR       0.86      0.82      0.84        45\n",
      "          CG       0.80      0.91      0.85        45\n",
      "          BE       0.93      0.87      0.90        45\n",
      "           N       0.86      0.82      0.84        45\n",
      "\n",
      "    accuracy                           0.86       405\n",
      "   macro avg       0.86      0.86      0.86       405\n",
      "weighted avg       0.86      0.86      0.86       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.299000</td>\n",
       "      <td>0.585833</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.836214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.375600</td>\n",
       "      <td>0.436690</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.869024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.476692</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.868833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>0.488855</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.508476</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-456 (score: 0.8716049382716049).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 3e-05\n",
      " {'test_loss': 0.4888548254966736, 'test_accuracy': 0.8716049382716049, 'test_macro-f1': 0.8710858494486842, 'test_runtime': 3.2276, 'test_samples_per_second': 125.481, 'test_steps_per_second': 4.028} \n",
      "\n",
      "accuracy 0.8716049382716049\n",
      "macro_f1 score: 0.8710858494486842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.95      0.87      0.91        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.90      0.96      0.92        45\n",
      "          HC       0.89      0.76      0.82        45\n",
      "          PL       0.80      0.82      0.81        45\n",
      "          CR       0.90      0.82      0.86        45\n",
      "          CG       0.85      0.87      0.86        45\n",
      "          BE       0.77      0.98      0.86        45\n",
      "           N       0.90      0.82      0.86        45\n",
      "\n",
      "    accuracy                           0.87       405\n",
      "   macro avg       0.88      0.87      0.87       405\n",
      "weighted avg       0.88      0.87      0.87       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.008900</td>\n",
       "      <td>0.507763</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>0.845536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.450362</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.504095</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.883928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.565888</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8839506172839506).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 5e-05\n",
      " {'test_loss': 0.5040954947471619, 'test_accuracy': 0.8839506172839506, 'test_macro-f1': 0.8839282543491177, 'test_runtime': 3.2377, 'test_samples_per_second': 125.088, 'test_steps_per_second': 4.015} \n",
      "\n",
      "accuracy 0.8839506172839506\n",
      "macro_f1 score: 0.8839282543491177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.89      0.91        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.89      0.91      0.90        45\n",
      "          HC       0.84      0.91      0.87        45\n",
      "          PL       0.83      0.84      0.84        45\n",
      "          CR       0.92      0.80      0.86        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.95      0.80      0.87        45\n",
      "           N       0.95      0.87      0.91        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.915900</td>\n",
       "      <td>0.554801</td>\n",
       "      <td>0.849383</td>\n",
       "      <td>0.848376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.521215</td>\n",
       "      <td>0.849383</td>\n",
       "      <td>0.849095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.607389</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.863736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.651541</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.853929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.670667</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.854030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8641975308641975).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 7e-05\n",
      " {'test_loss': 0.6073894500732422, 'test_accuracy': 0.8641975308641975, 'test_macro-f1': 0.8637355532004158, 'test_runtime': 3.222, 'test_samples_per_second': 125.7, 'test_steps_per_second': 4.035} \n",
      "\n",
      "accuracy 0.8641975308641975\n",
      "macro_f1 score: 0.8637355532004158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.91      0.87      0.89        45\n",
      "          NC       0.95      0.91      0.93        45\n",
      "          PW       0.88      0.93      0.90        45\n",
      "          HC       0.81      0.84      0.83        45\n",
      "          PL       0.85      0.73      0.79        45\n",
      "          CR       0.88      0.84      0.86        45\n",
      "          CG       0.76      0.98      0.85        45\n",
      "          BE       0.88      0.78      0.82        45\n",
      "           N       0.91      0.89      0.90        45\n",
      "\n",
      "    accuracy                           0.86       405\n",
      "   macro avg       0.87      0.86      0.86       405\n",
      "weighted avg       0.87      0.86      0.86       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.833700</td>\n",
       "      <td>0.541394</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.843951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272400</td>\n",
       "      <td>0.493623</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>0.644357</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.855104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.660733</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.639725</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.876427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-570 (score: 0.8765432098765432).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 9e-05\n",
      " {'test_loss': 0.6397249698638916, 'test_accuracy': 0.8765432098765432, 'test_macro-f1': 0.8764270157496328, 'test_runtime': 3.2245, 'test_samples_per_second': 125.602, 'test_steps_per_second': 4.032} \n",
      "\n",
      "accuracy 0.8765432098765432\n",
      "macro_f1 score: 0.8764270157496328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.95      0.87      0.91        45\n",
      "          NC       0.93      0.96      0.95        45\n",
      "          PW       0.88      0.96      0.91        45\n",
      "          HC       0.81      0.87      0.84        45\n",
      "          PL       0.82      0.82      0.82        45\n",
      "          CR       0.93      0.82      0.87        45\n",
      "          CG       0.82      0.93      0.87        45\n",
      "          BE       0.86      0.84      0.85        45\n",
      "           N       0.90      0.82      0.86        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.88      0.88      0.88       405\n",
      "weighted avg       0.88      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "learning_rate: 1e-05, acc: 0.8592592592592593, macro-f1: 0.859124237735564\n",
      "learning_rate: 3e-05, acc: 0.8716049382716049, macro-f1: 0.8710858494486842\n",
      "learning_rate: 5e-05, acc: 0.8839506172839506, macro-f1: 0.8839282543491177\n",
      "learning_rate: 7e-05, acc: 0.8641975308641975, macro-f1: 0.8637355532004158\n",
      "learning_rate: 9e-05, acc: 0.8765432098765432, macro-f1: 0.8764270157496328\n",
      "\n",
      "Best Model: learning_rate = 5e-05, acc = 0.8839506172839506, macro-f1 = 0.8839282543491177\n"
     ]
    }
   ],
   "source": [
    "learning_rate_list = [1e-5, 3e-5, 5e-5, 7e-5, 9e-5]\n",
    "\n",
    "best_learning_rate = 0\n",
    "best_acc = 0\n",
    "best_macro_f1 = 0\n",
    "\n",
    "acc_list = list()\n",
    "macro_f1_list = list()\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "  # reload pre-trained model\n",
    "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels=9)\n",
    "\n",
    "  # set training arguments\n",
    "  args = TrainingArguments(\n",
    "          output_dir = 'temp/',\n",
    "          evaluation_strategy = 'epoch',\n",
    "          save_strategy = 'epoch',\n",
    "          logging_strategy='epoch',\n",
    "          learning_rate=learning_rate,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "          weight_decay=weight_decay,\n",
    "          load_best_model_at_end=True,\n",
    "          metric_for_best_model='accuracy',\n",
    "  )\n",
    "\n",
    "  # set trainer\n",
    "  trainer = Trainer(\n",
    "          model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "          args=args,                  # training arguments, defined above\n",
    "          train_dataset=dataset_train,         # training dataset\n",
    "          eval_dataset=dataset_val,            # evaluation dataset\n",
    "          compute_metrics=compute_metrics\n",
    "  )\n",
    "\n",
    "  # train model\n",
    "  trainer.train() \n",
    "\n",
    "  # generate prediction\n",
    "  predictions = trainer.predict(dataset_val)\n",
    "  print(f'learning_rate: {learning_rate}\\n', predictions.metrics, '\\n')\n",
    "  y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "  # evaluate model performance\n",
    "  acc = accuracy_score(y_pred, predictions[1])\n",
    "  f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "  print(f'accuracy {acc}')\n",
    "  print(f'macro_f1 score: {f1}')\n",
    "  print(classification_report(predictions[1], y_pred,target_names=labels))\n",
    "  print('------------------------------------------------------------------------------------------------------')  \n",
    "  acc_list.append(acc)\n",
    "  macro_f1_list.append(f1)\n",
    "\n",
    "  # save best model hyperparameter\n",
    "  if best_acc < acc:\n",
    "    best_acc = acc\n",
    "    best_macro_f1 = f1\n",
    "    best_learning_rate = learning_rate\n",
    "\n",
    "print()\n",
    "for i in range(len(learning_rate_list)):\n",
    "  print(f'learning_rate: {learning_rate_list[i]}, acc: {acc_list[i]}, macro-f1: {macro_f1_list[i]}')\n",
    "print()\n",
    "print(f'Best Model: learning_rate = {best_learning_rate}, acc = {best_acc}, macro-f1 = {best_macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcMmfd9UWHTT"
   },
   "outputs": [],
   "source": [
    "learning_rate = best_learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxnNRttLgfRf"
   },
   "source": [
    "### per_device_train_batch_size & per_device_eval_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AH38fYZXgmf1",
    "outputId": "7b58d4da-b65d-4367-ec0b-23ccb4187dae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2280\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 09:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>0.542893</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.853657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.607841</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.870675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.764564</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.813010</td>\n",
       "      <td>0.879012</td>\n",
       "      <td>0.878999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.814536</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.881422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to temp/checkpoint-912\n",
      "Configuration saved in temp/checkpoint-912/config.json\n",
      "Model weights saved in temp/checkpoint-912/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to temp/checkpoint-1368\n",
      "Configuration saved in temp/checkpoint-1368/config.json\n",
      "Model weights saved in temp/checkpoint-1368/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to temp/checkpoint-1824\n",
      "Configuration saved in temp/checkpoint-1824/config.json\n",
      "Model weights saved in temp/checkpoint-1824/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to temp/checkpoint-2280\n",
      "Configuration saved in temp/checkpoint-2280/config.json\n",
      "Model weights saved in temp/checkpoint-2280/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-2280 (score: 0.8814814814814815).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 8\n",
      " {'test_loss': 0.8145357370376587, 'test_accuracy': 0.8814814814814815, 'test_macro-f1': 0.881421822936434, 'test_runtime': 3.5506, 'test_samples_per_second': 114.066, 'test_steps_per_second': 14.364} \n",
      "\n",
      "accuracy 0.8814814814814815\n",
      "macro_f1 score: 0.881421822936434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.91      0.89      0.90        45\n",
      "          NC       0.94      0.98      0.96        45\n",
      "          PW       0.91      0.96      0.93        45\n",
      "          HC       0.80      0.82      0.81        45\n",
      "          PL       0.81      0.84      0.83        45\n",
      "          CR       0.93      0.82      0.87        45\n",
      "          CG       0.81      0.96      0.88        45\n",
      "          BE       0.88      0.84      0.86        45\n",
      "           N       0.97      0.82      0.89        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1140\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1140' max='1140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1140/1140 07:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.818900</td>\n",
       "      <td>0.550773</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>0.832622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.247700</td>\n",
       "      <td>0.511368</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.579902</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.670860</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.863888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.637756</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-684\n",
      "Configuration saved in temp/checkpoint-684/config.json\n",
      "Model weights saved in temp/checkpoint-684/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-912\n",
      "Configuration saved in temp/checkpoint-912/config.json\n",
      "Model weights saved in temp/checkpoint-912/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-1140\n",
      "Configuration saved in temp/checkpoint-1140/config.json\n",
      "Model weights saved in temp/checkpoint-1140/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-456 (score: 0.8740740740740741).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 16\n",
      " {'test_loss': 0.5113683342933655, 'test_accuracy': 0.8740740740740741, 'test_macro-f1': 0.8734863226819791, 'test_runtime': 3.1614, 'test_samples_per_second': 128.109, 'test_steps_per_second': 8.224} \n",
      "\n",
      "accuracy 0.8740740740740741\n",
      "macro_f1 score: 0.8734863226819791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.89      0.89      0.89        45\n",
      "          NC       0.95      0.91      0.93        45\n",
      "          PW       0.88      0.98      0.93        45\n",
      "          HC       0.85      0.78      0.81        45\n",
      "          PL       0.82      0.80      0.81        45\n",
      "          CR       0.91      0.87      0.89        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.88      0.80      0.84        45\n",
      "           N       0.93      0.87      0.90        45\n",
      "\n",
      "    accuracy                           0.87       405\n",
      "   macro avg       0.88      0.87      0.87       405\n",
      "weighted avg       0.88      0.87      0.87       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.008900</td>\n",
       "      <td>0.507763</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>0.845536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.450362</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.504095</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.883928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.565888</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8839506172839506).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 32\n",
      " {'test_loss': 0.5040954947471619, 'test_accuracy': 0.8839506172839506, 'test_macro-f1': 0.8839282543491177, 'test_runtime': 3.2766, 'test_samples_per_second': 123.604, 'test_steps_per_second': 3.968} \n",
      "\n",
      "accuracy 0.8839506172839506\n",
      "macro_f1 score: 0.8839282543491177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.89      0.91        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.89      0.91      0.90        45\n",
      "          HC       0.84      0.91      0.87        45\n",
      "          PL       0.83      0.84      0.84        45\n",
      "          CR       0.92      0.80      0.86        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.95      0.80      0.87        45\n",
      "           N       0.95      0.87      0.91        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 285\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [285/285 07:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.322000</td>\n",
       "      <td>0.598194</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.838204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.482766</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.858343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174300</td>\n",
       "      <td>0.510223</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.504152</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.498470</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.863726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to temp/checkpoint-57\n",
      "Configuration saved in temp/checkpoint-57/config.json\n",
      "Model weights saved in temp/checkpoint-57/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to temp/checkpoint-171\n",
      "Configuration saved in temp/checkpoint-171/config.json\n",
      "Model weights saved in temp/checkpoint-171/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to temp/checkpoint-285\n",
      "Configuration saved in temp/checkpoint-285/config.json\n",
      "Model weights saved in temp/checkpoint-285/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-228 (score: 0.8716049382716049).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: __index_level_0__, sentence. If __index_level_0__, sentence are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 64\n",
      " {'test_loss': 0.5041520595550537, 'test_accuracy': 0.8716049382716049, 'test_macro-f1': 0.8712131672012459, 'test_runtime': 3.2475, 'test_samples_per_second': 124.711, 'test_steps_per_second': 2.156} \n",
      "\n",
      "accuracy 0.8716049382716049\n",
      "macro_f1 score: 0.8712131672012459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.89      0.91        45\n",
      "          NC       0.90      0.96      0.92        45\n",
      "          PW       0.91      0.93      0.92        45\n",
      "          HC       0.88      0.78      0.82        45\n",
      "          PL       0.80      0.80      0.80        45\n",
      "          CR       0.88      0.82      0.85        45\n",
      "          CG       0.83      0.89      0.86        45\n",
      "          BE       0.81      0.93      0.87        45\n",
      "           N       0.93      0.84      0.88        45\n",
      "\n",
      "    accuracy                           0.87       405\n",
      "   macro avg       0.87      0.87      0.87       405\n",
      "weighted avg       0.87      0.87      0.87       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "batch_size: 8, acc: 0.8814814814814815, macro-f1: 0.881421822936434\n",
      "batch_size: 16, acc: 0.8740740740740741, macro-f1: 0.8734863226819791\n",
      "batch_size: 32, acc: 0.8839506172839506, macro-f1: 0.8839282543491177\n",
      "batch_size: 64, acc: 0.8716049382716049, macro-f1: 0.8712131672012459\n",
      "\n",
      "Best Model: batch_size = 32, acc = 0.8839506172839506, macro-f1 = 0.8839282543491177\n"
     ]
    }
   ],
   "source": [
    "batch_size_list = [8, 16, 32, 64]\n",
    "\n",
    "best_batch_size = 0\n",
    "best_acc = 0\n",
    "best_macro_f1 = 0\n",
    "\n",
    "acc_list = list()\n",
    "macro_f1_list = list()\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "  # reload pre-trained model\n",
    "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels=9)\n",
    "\n",
    "  # set training arguments\n",
    "  args = TrainingArguments(\n",
    "          output_dir = 'temp/',\n",
    "          evaluation_strategy = 'epoch',\n",
    "          save_strategy = 'epoch',\n",
    "          logging_strategy='epoch',\n",
    "          learning_rate=learning_rate,\n",
    "          per_device_train_batch_size=batch_size,\n",
    "          per_device_eval_batch_size=batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "          weight_decay=weight_decay,\n",
    "          load_best_model_at_end=True,\n",
    "          metric_for_best_model='accuracy',\n",
    "  )\n",
    "\n",
    "  # set trainer\n",
    "  trainer = Trainer(\n",
    "          model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "          args=args,                  # training arguments, defined above\n",
    "          train_dataset=dataset_train,         # training dataset\n",
    "          eval_dataset=dataset_val,            # evaluation dataset\n",
    "          compute_metrics=compute_metrics\n",
    "  )\n",
    "\n",
    "  # train model\n",
    "  trainer.train() \n",
    "\n",
    "  # generate prediction\n",
    "  predictions = trainer.predict(dataset_val)\n",
    "  print(f'batch_size: {batch_size}\\n', predictions.metrics, '\\n')\n",
    "  y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "  # evaluate model performance\n",
    "  acc = accuracy_score(y_pred, predictions[1])\n",
    "  f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "  print(f'accuracy {acc}')\n",
    "  print(f'macro_f1 score: {f1}')\n",
    "  print(classification_report(predictions[1], y_pred,target_names=labels))\n",
    "  print('------------------------------------------------------------------------------------------------------') \n",
    "  acc_list.append(acc)\n",
    "  macro_f1_list.append(f1) \n",
    "\n",
    "  # save best model hyperparameter\n",
    "  if best_acc < acc:\n",
    "    best_acc = acc\n",
    "    best_macro_f1 = f1\n",
    "    best_batch_size = batch_size\n",
    "\n",
    "print()\n",
    "for i in range(len(batch_size_list)):\n",
    "  print(f'batch_size: {batch_size_list[i]}, acc: {acc_list[i]}, macro-f1: {macro_f1_list[i]}')\n",
    "print()\n",
    "print(f'Best Model: batch_size = {best_batch_size}, acc = {best_acc}, macro-f1 = {best_macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TwlVmPkPauu"
   },
   "outputs": [],
   "source": [
    "# though memory error occurred, best model is batch_size=16, with acc=0.86667, and f1=0.866847\n",
    "per_device_train_batch_size = best_batch_size\n",
    "per_device_eval_batch_size = best_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qP90JCr_WLMm"
   },
   "source": [
    "### weight_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Cu4QZleMWHan",
    "outputId": "dedfc651-95ba-4e8b-d540-673d1483ab27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.043500</td>\n",
       "      <td>0.530736</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.842236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.283200</td>\n",
       "      <td>0.524090</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.856423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110100</td>\n",
       "      <td>0.537023</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.587154</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.854326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.605676</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8666666666666667).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay: 0\n",
      " {'test_loss': 0.5370230674743652, 'test_accuracy': 0.8666666666666667, 'test_macro-f1': 0.8669536536810204, 'test_runtime': 3.1444, 'test_samples_per_second': 128.801, 'test_steps_per_second': 4.134} \n",
      "\n",
      "accuracy 0.8666666666666667\n",
      "macro_f1 score: 0.8669536536810204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.91      0.87      0.89        45\n",
      "          NC       0.96      0.96      0.96        45\n",
      "          PW       0.93      0.91      0.92        45\n",
      "          HC       0.86      0.80      0.83        45\n",
      "          PL       0.76      0.84      0.80        45\n",
      "          CR       0.89      0.87      0.88        45\n",
      "          CG       0.78      0.96      0.86        45\n",
      "          BE       0.84      0.80      0.82        45\n",
      "           N       0.92      0.80      0.86        45\n",
      "\n",
      "    accuracy                           0.87       405\n",
      "   macro avg       0.87      0.87      0.87       405\n",
      "weighted avg       0.87      0.87      0.87       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.008900</td>\n",
       "      <td>0.507763</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>0.845536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292700</td>\n",
       "      <td>0.450362</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.504095</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.883928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.553698</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.022600</td>\n",
       "      <td>0.565888</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8839506172839506).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay: 0.0001\n",
      " {'test_loss': 0.5040954947471619, 'test_accuracy': 0.8839506172839506, 'test_macro-f1': 0.8839282543491177, 'test_runtime': 3.1291, 'test_samples_per_second': 129.432, 'test_steps_per_second': 4.155} \n",
      "\n",
      "accuracy 0.8839506172839506\n",
      "macro_f1 score: 0.8839282543491177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.89      0.91        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.89      0.91      0.90        45\n",
      "          HC       0.84      0.91      0.87        45\n",
      "          PL       0.83      0.84      0.84        45\n",
      "          CR       0.92      0.80      0.86        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.95      0.80      0.87        45\n",
      "           N       0.95      0.87      0.91        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.008800</td>\n",
       "      <td>0.504999</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.850795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292000</td>\n",
       "      <td>0.448605</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.508958</td>\n",
       "      <td>0.879012</td>\n",
       "      <td>0.878792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.565963</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8790123456790123).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay: 0.001\n",
      " {'test_loss': 0.5089583992958069, 'test_accuracy': 0.8790123456790123, 'test_macro-f1': 0.8787919895229304, 'test_runtime': 3.1937, 'test_samples_per_second': 126.811, 'test_steps_per_second': 4.07} \n",
      "\n",
      "accuracy 0.8790123456790123\n",
      "macro_f1 score: 0.8787919895229304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.89      0.89      0.89        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.89      0.91      0.90        45\n",
      "          HC       0.84      0.91      0.87        45\n",
      "          PL       0.83      0.84      0.84        45\n",
      "          CR       0.92      0.80      0.86        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.95      0.80      0.87        45\n",
      "           N       0.95      0.82      0.88        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.88      0.88      0.88       405\n",
      "weighted avg       0.88      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.006400</td>\n",
       "      <td>0.508592</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.843470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.446480</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.508287</td>\n",
       "      <td>0.886420</td>\n",
       "      <td>0.886403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.562444</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.870775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.573611</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.875788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8864197530864197).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay: 0.01\n",
      " {'test_loss': 0.5082873702049255, 'test_accuracy': 0.8864197530864197, 'test_macro-f1': 0.8864032984191608, 'test_runtime': 3.1367, 'test_samples_per_second': 129.118, 'test_steps_per_second': 4.145} \n",
      "\n",
      "accuracy 0.8864197530864197\n",
      "macro_f1 score: 0.8864032984191608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.89      0.91        45\n",
      "          NC       0.90      0.98      0.94        45\n",
      "          PW       0.91      0.91      0.91        45\n",
      "          HC       0.85      0.89      0.87        45\n",
      "          PL       0.83      0.84      0.84        45\n",
      "          CR       0.92      0.80      0.86        45\n",
      "          CG       0.80      0.96      0.87        45\n",
      "          BE       0.93      0.84      0.88        45\n",
      "           N       0.95      0.87      0.91        45\n",
      "\n",
      "    accuracy                           0.89       405\n",
      "   macro avg       0.89      0.89      0.89       405\n",
      "weighted avg       0.89      0.89      0.89       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.009500</td>\n",
       "      <td>0.508765</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.850853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.287700</td>\n",
       "      <td>0.442499</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.511334</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.881443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.564866</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.876237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.545390</td>\n",
       "      <td>0.879012</td>\n",
       "      <td>0.878672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8814814814814815).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_decay: 0.1\n",
      " {'test_loss': 0.511333703994751, 'test_accuracy': 0.8814814814814815, 'test_macro-f1': 0.8814425383327618, 'test_runtime': 3.1717, 'test_samples_per_second': 127.693, 'test_steps_per_second': 4.099} \n",
      "\n",
      "accuracy 0.8814814814814815\n",
      "macro_f1 score: 0.8814425383327618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.95      0.91      0.93        45\n",
      "          NC       0.93      0.96      0.95        45\n",
      "          PW       0.91      0.91      0.91        45\n",
      "          HC       0.80      0.91      0.85        45\n",
      "          PL       0.83      0.78      0.80        45\n",
      "          CR       0.92      0.80      0.86        45\n",
      "          CG       0.77      0.98      0.86        45\n",
      "          BE       0.95      0.80      0.87        45\n",
      "           N       0.91      0.89      0.90        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "weight_decay: 0, acc: 0.8666666666666667, macro-f1: 0.8669536536810204\n",
      "weight_decay: 0.0001, acc: 0.8839506172839506, macro-f1: 0.8839282543491177\n",
      "weight_decay: 0.001, acc: 0.8790123456790123, macro-f1: 0.8787919895229304\n",
      "weight_decay: 0.01, acc: 0.8864197530864197, macro-f1: 0.8864032984191608\n",
      "weight_decay: 0.1, acc: 0.8814814814814815, macro-f1: 0.8814425383327618\n",
      "\n",
      "Best Model: weight_decay = 0.01, acc = 0.8864197530864197, macro-f1 = 0.8864032984191608\n"
     ]
    }
   ],
   "source": [
    "weight_decay_list = [0, 0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "best_weight_decay = 0\n",
    "best_acc = 0\n",
    "best_macro_f1 = 0\n",
    "\n",
    "acc_list = list()\n",
    "macro_f1_list = list()\n",
    "\n",
    "for weight_decay in weight_decay_list:\n",
    "  # reload pre-trained model\n",
    "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels=9)\n",
    "\n",
    "  # set training arguments\n",
    "  args = TrainingArguments(\n",
    "          output_dir = 'temp/',\n",
    "          evaluation_strategy = 'epoch',\n",
    "          save_strategy = 'epoch',\n",
    "          logging_strategy='epoch',\n",
    "          learning_rate=learning_rate,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "          weight_decay=weight_decay,\n",
    "          load_best_model_at_end=True,\n",
    "          metric_for_best_model='accuracy',\n",
    "  )\n",
    "\n",
    "  # set trainer\n",
    "  trainer = Trainer(\n",
    "          model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "          args=args,                  # training arguments, defined above\n",
    "          train_dataset=dataset_train,         # training dataset\n",
    "          eval_dataset=dataset_val,            # evaluation dataset\n",
    "          compute_metrics=compute_metrics\n",
    "  )\n",
    "\n",
    "  # train model\n",
    "  trainer.train() \n",
    "\n",
    "  # generate prediction\n",
    "  predictions = trainer.predict(dataset_val)\n",
    "  print(f'weight_decay: {weight_decay}\\n', predictions.metrics, '\\n')\n",
    "  y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "  # evaluate model performance\n",
    "  acc = accuracy_score(y_pred, predictions[1])\n",
    "  f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "  print(f'accuracy {acc}')\n",
    "  print(f'macro_f1 score: {f1}')\n",
    "  print(classification_report(predictions[1], y_pred,target_names=labels))\n",
    "  print('------------------------------------------------------------------------------------------------------') \n",
    "  acc_list.append(acc)\n",
    "  macro_f1_list.append(f1)   \n",
    "\n",
    "  # save best model hyperparameter\n",
    "  if best_acc < acc:\n",
    "    best_acc = acc\n",
    "    best_macro_f1 = f1\n",
    "    best_weight_decay = weight_decay\n",
    "\n",
    "print()\n",
    "for i in range(len(weight_decay_list)):\n",
    "  print(f'weight_decay: {weight_decay_list[i]}, acc: {acc_list[i]}, macro-f1: {macro_f1_list[i]}')\n",
    "print()\n",
    "print(f'Best Model: weight_decay = {best_weight_decay}, acc = {best_acc}, macro-f1 = {best_macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "31x76OUhWHcv"
   },
   "outputs": [],
   "source": [
    "weight_decay = best_weight_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz74tPw0WvPK"
   },
   "source": [
    "### num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nsG7V7GLWzxQ",
    "outputId": "f37e87ce-debf-4035-8010-7a706c179705"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [342/342 04:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.015900</td>\n",
       "      <td>0.504264</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.838765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.425045</td>\n",
       "      <td>0.879012</td>\n",
       "      <td>0.878733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>0.463089</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.869000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-228 (score: 0.8790123456790123).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 3\n",
      " {'test_loss': 0.425045371055603, 'test_accuracy': 0.8790123456790123, 'test_macro-f1': 0.8787334031764286, 'test_runtime': 3.1357, 'test_samples_per_second': 129.159, 'test_steps_per_second': 4.146} \n",
      "\n",
      "accuracy 0.8790123456790123\n",
      "macro_f1 score: 0.8787334031764286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.87      0.91      0.89        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.89      0.91      0.90        45\n",
      "          HC       0.86      0.82      0.84        45\n",
      "          PL       0.84      0.82      0.83        45\n",
      "          CR       0.90      0.82      0.86        45\n",
      "          CG       0.87      0.91      0.89        45\n",
      "          BE       0.82      0.91      0.86        45\n",
      "           N       0.95      0.84      0.89        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.88      0.88      0.88       405\n",
      "weighted avg       0.88      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [456/456 05:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.110900</td>\n",
       "      <td>0.534662</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>0.833613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.295500</td>\n",
       "      <td>0.459643</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.482000</td>\n",
       "      <td>0.891358</td>\n",
       "      <td>0.891147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>0.523136</td>\n",
       "      <td>0.879012</td>\n",
       "      <td>0.878830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.891358024691358).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 4\n",
      " {'test_loss': 0.48199960589408875, 'test_accuracy': 0.891358024691358, 'test_macro-f1': 0.8911469839728205, 'test_runtime': 3.1295, 'test_samples_per_second': 129.412, 'test_steps_per_second': 4.154} \n",
      "\n",
      "accuracy 0.891358024691358\n",
      "macro_f1 score: 0.8911469839728205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.91      0.89      0.90        45\n",
      "          NC       0.96      0.98      0.97        45\n",
      "          PW       0.91      0.93      0.92        45\n",
      "          HC       0.85      0.89      0.87        45\n",
      "          PL       0.86      0.80      0.83        45\n",
      "          CR       0.91      0.89      0.90        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.95      0.80      0.87        45\n",
      "           N       0.93      0.87      0.90        45\n",
      "\n",
      "    accuracy                           0.89       405\n",
      "   macro avg       0.90      0.89      0.89       405\n",
      "weighted avg       0.90      0.89      0.89       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='570' max='570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [570/570 07:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.036500</td>\n",
       "      <td>0.508233</td>\n",
       "      <td>0.829630</td>\n",
       "      <td>0.828804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.488662</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.856963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>0.493356</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.863551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046200</td>\n",
       "      <td>0.581020</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.865433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.582234</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-456 (score: 0.8666666666666667).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 5\n",
      " {'test_loss': 0.5810199975967407, 'test_accuracy': 0.8666666666666667, 'test_macro-f1': 0.8654333121063111, 'test_runtime': 3.135, 'test_samples_per_second': 129.185, 'test_steps_per_second': 4.147} \n",
      "\n",
      "accuracy 0.8666666666666667\n",
      "macro_f1 score: 0.8654333121063111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.91      0.87      0.89        45\n",
      "          NC       0.92      0.98      0.95        45\n",
      "          PW       0.91      0.96      0.93        45\n",
      "          HC       0.89      0.73      0.80        45\n",
      "          PL       0.83      0.76      0.79        45\n",
      "          CR       0.87      0.87      0.87        45\n",
      "          CG       0.83      0.89      0.86        45\n",
      "          BE       0.78      0.93      0.85        45\n",
      "           N       0.88      0.82      0.85        45\n",
      "\n",
      "    accuracy                           0.87       405\n",
      "   macro avg       0.87      0.87      0.87       405\n",
      "weighted avg       0.87      0.87      0.87       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='684' max='684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [684/684 08:39, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.008000</td>\n",
       "      <td>0.513345</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.840920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.465019</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.876232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.495201</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.881259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.594389</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.613164</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.871718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.598123</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.869200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-684\n",
      "Configuration saved in temp/checkpoint-684/config.json\n",
      "Model weights saved in temp/checkpoint-684/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8814814814814815).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 6\n",
      " {'test_loss': 0.495200514793396, 'test_accuracy': 0.8814814814814815, 'test_macro-f1': 0.8812589156114657, 'test_runtime': 3.1528, 'test_samples_per_second': 128.457, 'test_steps_per_second': 4.123} \n",
      "\n",
      "accuracy 0.8814814814814815\n",
      "macro_f1 score: 0.8812589156114657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.93      0.89      0.91        45\n",
      "          NC       0.91      0.96      0.93        45\n",
      "          PW       0.91      0.93      0.92        45\n",
      "          HC       0.81      0.87      0.84        45\n",
      "          PL       0.85      0.78      0.81        45\n",
      "          CR       0.93      0.82      0.87        45\n",
      "          CG       0.79      0.98      0.87        45\n",
      "          BE       0.95      0.82      0.88        45\n",
      "           N       0.89      0.89      0.89        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 7\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 798\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='798' max='798' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [798/798 10:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.049100</td>\n",
       "      <td>0.542556</td>\n",
       "      <td>0.846914</td>\n",
       "      <td>0.846659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.464724</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.128700</td>\n",
       "      <td>0.506579</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.876002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.598104</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.623506</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.876646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.646460</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>0.876416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.660580</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.868983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-684\n",
      "Configuration saved in temp/checkpoint-684/config.json\n",
      "Model weights saved in temp/checkpoint-684/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-798\n",
      "Configuration saved in temp/checkpoint-798/config.json\n",
      "Model weights saved in temp/checkpoint-798/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8765432098765432).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 7\n",
      " {'test_loss': 0.5065791606903076, 'test_accuracy': 0.8765432098765432, 'test_macro-f1': 0.8760022548321539, 'test_runtime': 3.1505, 'test_samples_per_second': 128.551, 'test_steps_per_second': 4.126} \n",
      "\n",
      "accuracy 0.8765432098765432\n",
      "macro_f1 score: 0.8760022548321539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.87      0.91      0.89        45\n",
      "          NC       0.94      0.98      0.96        45\n",
      "          PW       0.93      0.91      0.92        45\n",
      "          HC       0.82      0.89      0.85        45\n",
      "          PL       0.80      0.82      0.81        45\n",
      "          CR       0.90      0.84      0.87        45\n",
      "          CG       0.80      0.98      0.88        45\n",
      "          BE       0.92      0.78      0.84        45\n",
      "           N       0.95      0.78      0.85        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.88      0.88      0.88       405\n",
      "weighted avg       0.88      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 912\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='912' max='912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [912/912 11:33, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.009500</td>\n",
       "      <td>0.517220</td>\n",
       "      <td>0.834568</td>\n",
       "      <td>0.834341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.463216</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.532203</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.883529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.594813</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.685785</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.738730</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.861668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.776841</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.771784</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-114\n",
      "Configuration saved in temp/checkpoint-114/config.json\n",
      "Model weights saved in temp/checkpoint-114/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-342\n",
      "Configuration saved in temp/checkpoint-342/config.json\n",
      "Model weights saved in temp/checkpoint-342/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-570\n",
      "Configuration saved in temp/checkpoint-570/config.json\n",
      "Model weights saved in temp/checkpoint-570/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-684\n",
      "Configuration saved in temp/checkpoint-684/config.json\n",
      "Model weights saved in temp/checkpoint-684/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-798\n",
      "Configuration saved in temp/checkpoint-798/config.json\n",
      "Model weights saved in temp/checkpoint-798/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to temp/checkpoint-912\n",
      "Configuration saved in temp/checkpoint-912/config.json\n",
      "Model weights saved in temp/checkpoint-912/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-342 (score: 0.8839506172839506).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 8\n",
      " {'test_loss': 0.532203197479248, 'test_accuracy': 0.8839506172839506, 'test_macro-f1': 0.8835294937185111, 'test_runtime': 3.144, 'test_samples_per_second': 128.818, 'test_steps_per_second': 4.135} \n",
      "\n",
      "accuracy 0.8839506172839506\n",
      "macro_f1 score: 0.8835294937185111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.97      0.87      0.92        45\n",
      "          NC       0.89      0.93      0.91        45\n",
      "          PW       0.90      0.96      0.92        45\n",
      "          HC       0.78      0.89      0.83        45\n",
      "          PL       0.88      0.84      0.86        45\n",
      "          CR       0.90      0.80      0.85        45\n",
      "          CG       0.84      0.93      0.88        45\n",
      "          BE       0.92      0.78      0.84        45\n",
      "           N       0.90      0.96      0.92        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "num_train_epochs: 3, acc: 0.8790123456790123, macro-f1: 0.8787334031764286\n",
      "num_train_epochs: 4, acc: 0.891358024691358, macro-f1: 0.8911469839728205\n",
      "num_train_epochs: 5, acc: 0.8666666666666667, macro-f1: 0.8654333121063111\n",
      "num_train_epochs: 6, acc: 0.8814814814814815, macro-f1: 0.8812589156114657\n",
      "num_train_epochs: 7, acc: 0.8765432098765432, macro-f1: 0.8760022548321539\n",
      "num_train_epochs: 8, acc: 0.8839506172839506, macro-f1: 0.8835294937185111\n",
      "\n",
      "Best Model: num_train_epochs = 4, acc = 0.891358024691358, macro-f1 = 0.8911469839728205\n"
     ]
    }
   ],
   "source": [
    "num_train_epochs_list = [3, 4, 5, 6, 7, 8]\n",
    "\n",
    "best_num_train_epochs = 0\n",
    "best_acc = 0\n",
    "best_macro_f1 = 0\n",
    "\n",
    "acc_list = list()\n",
    "macro_f1_list = list()\n",
    "\n",
    "for num_train_epochs in num_train_epochs_list:\n",
    "  # reload pre-trained model\n",
    "  model = BertForSequenceClassification.from_pretrained(model_name,num_labels=9)\n",
    "\n",
    "  # set training arguments\n",
    "  args = TrainingArguments(\n",
    "          output_dir = 'temp/',\n",
    "          evaluation_strategy = 'epoch',\n",
    "          save_strategy = 'epoch',\n",
    "          logging_strategy='epoch',\n",
    "          learning_rate=learning_rate,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "          weight_decay=weight_decay,\n",
    "          load_best_model_at_end=True,\n",
    "          metric_for_best_model='accuracy',\n",
    "  )\n",
    "\n",
    "  # set trainer\n",
    "  trainer = Trainer(\n",
    "          model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "          args=args,                  # training arguments, defined above\n",
    "          train_dataset=dataset_train,         # training dataset\n",
    "          eval_dataset=dataset_val,            # evaluation dataset\n",
    "          compute_metrics=compute_metrics\n",
    "  )\n",
    "\n",
    "  # train model\n",
    "  trainer.train() \n",
    "\n",
    "  # generate prediction\n",
    "  predictions = trainer.predict(dataset_val)\n",
    "  print(f'num_train_epochs: {num_train_epochs}\\n', predictions.metrics, '\\n')\n",
    "  y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "  # evaluate model performance\n",
    "  acc = accuracy_score(y_pred, predictions[1])\n",
    "  f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "  print(f'accuracy {acc}')\n",
    "  print(f'macro_f1 score: {f1}')\n",
    "  print(classification_report(predictions[1], y_pred,target_names=labels))\n",
    "  print('------------------------------------------------------------------------------------------------------')\n",
    "  acc_list.append(acc)\n",
    "  macro_f1_list.append(f1)  \n",
    "\n",
    "  # save best model hyperparameter\n",
    "  if best_acc < acc:\n",
    "    best_acc = acc\n",
    "    best_macro_f1 = f1\n",
    "    best_num_train_epochs = num_train_epochs\n",
    "\n",
    "print()\n",
    "for i in range(len(num_train_epochs_list)):\n",
    "  print(f'num_train_epochs: {num_train_epochs_list[i]}, acc: {acc_list[i]}, macro-f1: {macro_f1_list[i]}')\n",
    "print()\n",
    "print(f'Best Model: num_train_epochs = {best_num_train_epochs}, acc = {best_acc}, macro-f1 = {best_macro_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "990GhUo3Wz02"
   },
   "outputs": [],
   "source": [
    "num_train_epochs = best_num_train_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVQUmYSdW1ER"
   },
   "source": [
    "## **Final Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CRRwdDNsk9yU"
   },
   "outputs": [],
   "source": [
    "# best hyperparameters values\n",
    "learning_rate = 5e-5\n",
    "per_device_train_batch_size = per_device_eval_batch_size = 16\n",
    "num_train_epochs = 4\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v6YMtle6AnDr",
    "outputId": "35d95564-69b8-43f3-e0bb-0ade03beabf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3645\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 912\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='912' max='912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [912/912 06:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro-f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.853200</td>\n",
       "      <td>0.539501</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.858369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.261600</td>\n",
       "      <td>0.527645</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.521975</td>\n",
       "      <td>0.883951</td>\n",
       "      <td>0.883336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>0.607058</td>\n",
       "      <td>0.871605</td>\n",
       "      <td>0.870977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-228\n",
      "Configuration saved in temp/checkpoint-228/config.json\n",
      "Model weights saved in temp/checkpoint-228/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-456\n",
      "Configuration saved in temp/checkpoint-456/config.json\n",
      "Model weights saved in temp/checkpoint-456/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-684\n",
      "Configuration saved in temp/checkpoint-684/config.json\n",
      "Model weights saved in temp/checkpoint-684/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to temp/checkpoint-912\n",
      "Configuration saved in temp/checkpoint-912/config.json\n",
      "Model weights saved in temp/checkpoint-912/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from temp/checkpoint-684 (score: 0.8839506172839506).\n",
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 405\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_epochs: 4\n",
      " {'test_loss': 0.5219752788543701, 'test_accuracy': 0.8839506172839506, 'test_macro-f1': 0.88333649505779, 'test_runtime': 3.1056, 'test_samples_per_second': 130.409, 'test_steps_per_second': 8.372} \n",
      "\n",
      "accuracy 0.8839506172839506\n",
      "macro_f1 score: 0.88333649505779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.89      0.89      0.89        45\n",
      "          NC       0.94      0.98      0.96        45\n",
      "          PW       0.93      0.93      0.93        45\n",
      "          HC       0.90      0.78      0.83        45\n",
      "          PL       0.84      0.80      0.82        45\n",
      "          CR       0.87      0.87      0.87        45\n",
      "          CG       0.84      0.93      0.88        45\n",
      "          BE       0.84      0.91      0.87        45\n",
      "           N       0.93      0.87      0.90        45\n",
      "\n",
      "    accuracy                           0.88       405\n",
      "   macro avg       0.89      0.88      0.88       405\n",
      "weighted avg       0.89      0.88      0.88       405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reload pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(model_name,num_labels=9)\n",
    "\n",
    "# set training arguments\n",
    "args = TrainingArguments(\n",
    "        output_dir = 'temp/',\n",
    "        evaluation_strategy = 'epoch',\n",
    "        save_strategy = 'epoch',\n",
    "        logging_strategy='epoch',\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "# set trainer\n",
    "trainer = Trainer(\n",
    "        model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        args=args,                  # training arguments, defined above\n",
    "        train_dataset=dataset_train,         # training dataset\n",
    "        eval_dataset=dataset_val,            # evaluation dataset\n",
    "        compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# train model\n",
    "trainer.train() \n",
    "\n",
    "# generate validation set prediction\n",
    "predictions = trainer.predict(dataset_val)\n",
    "print(f'num_train_epochs: {num_train_epochs}\\n', predictions.metrics, '\\n')\n",
    "y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "# evaluate model performance on validation set\n",
    "acc = accuracy_score(y_pred, predictions[1])\n",
    "f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "print(f'accuracy {acc}')\n",
    "print(f'macro_f1 score: {f1}')\n",
    "print(classification_report(predictions[1], y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xACsnCLNQH6K"
   },
   "source": [
    "## **Prediction on Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "0PRjMoe8N_iL",
    "outputId": "952e4adc-9f0c-4ab4-a27e-8fc7d8bc47ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, __index_level_0__. If sentence, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 450\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8977777777777778\n",
      "macro_f1 score: 0.8975227265895112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CC       0.87      0.96      0.91        50\n",
      "          NC       0.90      0.90      0.90        50\n",
      "          PW       0.88      0.92      0.90        50\n",
      "          HC       0.93      0.84      0.88        50\n",
      "          PL       0.85      0.82      0.84        50\n",
      "          CR       0.88      0.88      0.88        50\n",
      "          CG       0.96      0.88      0.92        50\n",
      "          BE       0.87      0.94      0.90        50\n",
      "           N       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.90       450\n",
      "   macro avg       0.90      0.90      0.90       450\n",
      "weighted avg       0.90      0.90      0.90       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate prediction\n",
    "predictions = trainer.predict(dataset_test)\n",
    "y_pred = np.array([np.argmax(pred) for pred in predictions[0]])\n",
    "\n",
    "# evaluate model performance\n",
    "f1 = f1_score(predictions[1], y_pred, average='macro')\n",
    "print('accuracy %s' % accuracy_score(y_pred, predictions[1]))\n",
    "print(f'macro_f1 score: {f1}')\n",
    "print(classification_report(predictions[1], y_pred,target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "3Js9jZFHOHVr",
    "outputId": "43b22c4e-45c4-476d-8211-ddf4e6a5d613"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f50e8b2cf50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot confusion matrix\n",
    "cm = confusion_matrix(predictions[1], y_pred , normalize='pred')\n",
    "cmp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbZ3VoFcAa5f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UROP_bert.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04b360c8ca1c40e1a67e731a7da357e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "05b0e5057bc5420590c193bc1a2c1527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "063cb2cc34204b11bf8577b9dd6feb1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_074333194c95425bb3c4819c1efc0c07",
       "IPY_MODEL_3c66e813c83a4ae19e4fde1c6281cf98",
       "IPY_MODEL_16563c0a5d56425f8a8601954699d0b9"
      ],
      "layout": "IPY_MODEL_d8dde5f76b48491f889823a5d158c784"
     }
    },
    "06df290212cd4dce9dee6850731cb43e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "074333194c95425bb3c4819c1efc0c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d2d814a03e64972aae6d439a9dc6f57",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_42768db2dbe1450ebe28bdf42ea035ea",
      "value": "100%"
     }
    },
    "11e3a67c3c99464c865b4a251d1cb8b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13ff27616bec449ab422ec112fba008c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16563c0a5d56425f8a8601954699d0b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35c4d256528f4fa29f1164860a3cb240",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a42c673b846416daa467e2ad1295fee",
      "value": " 4/4 [00:03&lt;00:00,  1.35ba/s]"
     }
    },
    "195aa78cdb97457283b581d2593b74ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf4c061b877442ef833e35c6394417cb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9dd4b3bc280a4ea0aa52545659fa59c8",
      "value": " 570/570 [00:00&lt;00:00, 13.5kB/s]"
     }
    },
    "1a8c273f4019462b90c58707d85aaf1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a42c673b846416daa467e2ad1295fee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d2d814a03e64972aae6d439a9dc6f57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3084b2c0f4224d02a9930010fe8bb464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "31b58fdf2a454a42a1daf7bb4af135e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3361842b7d6d4bc99d7f433dcdb92fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5528b219a3e2452abe0a7b51514717fd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_05b0e5057bc5420590c193bc1a2c1527",
      "value": 1
     }
    },
    "35c4d256528f4fa29f1164860a3cb240": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "385d8170daa54770976277e2203ecdc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a56f4ad0b8e4503a5e9062b621d0734": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c66e813c83a4ae19e4fde1c6281cf98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d75cbe4f57744c61a97d932895c03674",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3084b2c0f4224d02a9930010fe8bb464",
      "value": 4
     }
    },
    "42768db2dbe1450ebe28bdf42ea035ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "435acf4cc6c9403b884282e8ffe8a719": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "44302aa2ce354b12b36a78e1754d4921": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45a1ff6c483c4778975d23b1678a20ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d9d40854b84490789553234e5a35a40",
       "IPY_MODEL_3361842b7d6d4bc99d7f433dcdb92fad",
       "IPY_MODEL_e526a5a0774d4f11ba4a930c96f4acde"
      ],
      "layout": "IPY_MODEL_9acf6884b3d84c35bab7426ccb8b23a2"
     }
    },
    "4702b9ef04b64b76b119ead21ffe3c01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b540654eb65490ba6248f09025482d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bf0f86104944eb091686b09bd9f3703": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4702b9ef04b64b76b119ead21ffe3c01",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d5826321f95e4e8ab5be15c466fa305c",
      "value": " 420M/420M [00:07&lt;00:00, 56.8MB/s]"
     }
    },
    "51cacaebc8b945ad985e04a191abf8cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52322215b3f44c5d8474b541d736f1ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3a56f4ad0b8e4503a5e9062b621d0734",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_385d8170daa54770976277e2203ecdc8",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "5316e1b0beb74b4bb883ee7d0248cae5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79feb316f4624f42abe2ee960432f70b",
       "IPY_MODEL_9023a6bc41a54024b100c929e431c574",
       "IPY_MODEL_9470fa1726f74865850bff4e4588785d"
      ],
      "layout": "IPY_MODEL_7beffc1cc87b4308beaecc7cd59e0a98"
     }
    },
    "545acd2b59ca4d85a33f45caa1b131e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf04d1efdce24e459fc3342bdfbbdf05",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a3943813f7f3402e8edcaa673550ab0a",
      "value": "100%"
     }
    },
    "5528b219a3e2452abe0a7b51514717fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56edee92c70441b9af9f508499092211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee55d874ecfe46449d3b50403395f48d",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74f5030c80a54244b59431a402f2eb60",
      "value": 28
     }
    },
    "58faba1e48274d138778a1087ebafe06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1bd8fd10ff54964883518aff23f2509",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_435acf4cc6c9403b884282e8ffe8a719",
      "value": 440473133
     }
    },
    "5ae2706f9e9846f49315355f922ef150": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b540654eb65490ba6248f09025482d7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f6c1cbacce68433bb90fcaecb518139b",
      "value": " 28.0/28.0 [00:00&lt;00:00, 813B/s]"
     }
    },
    "5e771f6e6b9b4eceac24da3921bc2236": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "717b37ed7e844b28b4fbf8c84b1d5b0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74f5030c80a54244b59431a402f2eb60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "79feb316f4624f42abe2ee960432f70b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d64fd3c9e131424e89ccca026e262bef",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_edb6570cd8ed4e1b89a9a5f96b3152cf",
      "value": "Downloading vocab.txt: 100%"
     }
    },
    "7aea2ca670b346e19dc7e78a9b7959a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7beffc1cc87b4308beaecc7cd59e0a98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d03510396b743a7bb47481f0d52000e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_717b37ed7e844b28b4fbf8c84b1d5b0c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d16104a6ae0445fea2301e0d93083dac",
      "value": " 1/1 [00:00&lt;00:00,  2.37ba/s]"
     }
    },
    "901f1c3d78ec41ff8eceed365dd19617": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9023a6bc41a54024b100c929e431c574": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e771f6e6b9b4eceac24da3921bc2236",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_04b360c8ca1c40e1a67e731a7da357e4",
      "value": 231508
     }
    },
    "9470fa1726f74865850bff4e4588785d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a8c273f4019462b90c58707d85aaf1f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_cecf22af54f04ba895921837c93ab13a",
      "value": " 226k/226k [00:00&lt;00:00, 2.42MB/s]"
     }
    },
    "9ab9ed080bfb45adb2fa2a273d0df72e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9acf6884b3d84c35bab7426ccb8b23a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c8461ed6ed94d2eb09052d0fea5fed9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d59614f0b854d9794763381bfb8d7a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13ff27616bec449ab422ec112fba008c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d9b6126b6b84063bf126056e306fa88",
      "value": 1
     }
    },
    "9d81803847ea4539a746100dd1da99b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_52322215b3f44c5d8474b541d736f1ca",
       "IPY_MODEL_58faba1e48274d138778a1087ebafe06",
       "IPY_MODEL_4bf0f86104944eb091686b09bd9f3703"
      ],
      "layout": "IPY_MODEL_d945141252824e2c9503ff72414d0d4a"
     }
    },
    "9d9b6126b6b84063bf126056e306fa88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d9d40854b84490789553234e5a35a40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a20a1f2a8e124ee2839c8446da973de7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_9ab9ed080bfb45adb2fa2a273d0df72e",
      "value": "100%"
     }
    },
    "9dd4b3bc280a4ea0aa52545659fa59c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a20a1f2a8e124ee2839c8446da973de7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2a793b2c70342bb8197b0118257bc25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7f7bfc413164704801f0371f4c484a6",
       "IPY_MODEL_a9db3bd1c5e3463a98718ee9ec747906",
       "IPY_MODEL_195aa78cdb97457283b581d2593b74ff"
      ],
      "layout": "IPY_MODEL_44302aa2ce354b12b36a78e1754d4921"
     }
    },
    "a3943813f7f3402e8edcaa673550ab0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9db3bd1c5e3463a98718ee9ec747906": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0a9888ac2da45d395e79c18ff52ba6a",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7aea2ca670b346e19dc7e78a9b7959a1",
      "value": 570
     }
    },
    "c77926deb85142509fc8dd5f4557f481": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd3ab6890ec145a0abe3af2330886291": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9ca713f5666406181e97d8b36a7c142",
       "IPY_MODEL_56edee92c70441b9af9f508499092211",
       "IPY_MODEL_5ae2706f9e9846f49315355f922ef150"
      ],
      "layout": "IPY_MODEL_dca9fd04fe5e400d972d11be330a25f0"
     }
    },
    "cecf22af54f04ba895921837c93ab13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf04d1efdce24e459fc3342bdfbbdf05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf4c061b877442ef833e35c6394417cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d16104a6ae0445fea2301e0d93083dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d5826321f95e4e8ab5be15c466fa305c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d64fd3c9e131424e89ccca026e262bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d75cbe4f57744c61a97d932895c03674": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8dde5f76b48491f889823a5d158c784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d945141252824e2c9503ff72414d0d4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9ca713f5666406181e97d8b36a7c142": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_901f1c3d78ec41ff8eceed365dd19617",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_31b58fdf2a454a42a1daf7bb4af135e3",
      "value": "Downloading tokenizer_config.json: 100%"
     }
    },
    "dca9fd04fe5e400d972d11be330a25f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0a9888ac2da45d395e79c18ff52ba6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1bd8fd10ff54964883518aff23f2509": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e526a5a0774d4f11ba4a930c96f4acde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51cacaebc8b945ad985e04a191abf8cc",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_06df290212cd4dce9dee6850731cb43e",
      "value": " 1/1 [00:00&lt;00:00,  2.63ba/s]"
     }
    },
    "edb6570cd8ed4e1b89a9a5f96b3152cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee55d874ecfe46449d3b50403395f48d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6c1cbacce68433bb90fcaecb518139b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7f7bfc413164704801f0371f4c484a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11e3a67c3c99464c865b4a251d1cb8b8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c77926deb85142509fc8dd5f4557f481",
      "value": "Downloading config.json: 100%"
     }
    },
    "fe9db4c873d946c6a9a75698c8114836": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_545acd2b59ca4d85a33f45caa1b131e2",
       "IPY_MODEL_9d59614f0b854d9794763381bfb8d7a5",
       "IPY_MODEL_7d03510396b743a7bb47481f0d52000e"
      ],
      "layout": "IPY_MODEL_9c8461ed6ed94d2eb09052d0fea5fed9"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
